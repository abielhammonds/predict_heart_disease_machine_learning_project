{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are some things I am curious about, after exploring the data:**\n",
    "1. Do any of the features strongly predict heart disease on their own?\n",
    "2. Which combinations of features boost heart disease prediction the most?\n",
    "3. Are any of the features less related...unless combined with others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But first, I need to select an appropriate machine learning algorithm.**\n",
    "\n",
    "[These are the important considerations:](https://www.kdnuggets.com/2020/05/guide-choose-right-machine-learning-algorithm.html#:~:text=%20An%20easy%20guide%20to%20choose%20the%20right,time.%20Higher%20accuracy%20typically%20means%20higher...%20More%20)\n",
    "\n",
    "1. *Size of the training data (small in this case)*\n",
    "\n",
    "    if the training data is smal or if the dataset has a small number of observations/high number of features \n",
    "    choose algorithms with high bias/low variance like Linear regression, Naïve Bayes, or Linear SVM.\n",
    "    \n",
    "    If the training data is large and the number of observations is higher, compared to the number of \n",
    "    features, you can use low bias/high variance algorithms like KNN, Decision trees, or kernel SVM.\n",
    "    \n",
    "\n",
    "2. *Desired Accuracy and/or Interpretability of the output (interpretability in this case)*\n",
    "\n",
    "    Accuracy of a model means that the function predicts a response value for a given observation, which is \n",
    "    close to the true response value for that observation. \n",
    "    \n",
    "    A highly interpretable algorithm (restrictive models like Linear Regression) means that one can easily \n",
    "    understand how any individual predictor is associated with the response while the flexible models give \n",
    "    higher accuracy at the cost of low interpretability.\n",
    "    \n",
    "    \n",
    "3.  *Speed or Training time (non-issue for this small dataset)*\n",
    "\n",
    "    Higher accuracy typically means higher training time. Also, algorithms require more time to train on \n",
    "    large training data. In real-world applications, the choice of algorithm is driven by these two factors \n",
    "    predominantly.\n",
    "\n",
    "    Algorithms like Naïve Bayes and Linear and Logistic regression are easy to implement and quick to run. \n",
    "    Algorithms like SVM, which involve tuning of parameters, Neural networks with high convergence time, and \n",
    "    random forests, need a lot of time to train the data.\n",
    "    \n",
    "    \n",
    "4. *Linearity (to be determined)*\n",
    "\n",
    "    The best way to find out the linearity is to either fit a linear line or run a logistic regression or SVM \n",
    "    and check for residual errors. A higher error means the data is not linear and would need complex \n",
    "    algorithms to fit.\n",
    "    \n",
    "\n",
    "5. *Number of features (small in this case)*\n",
    "\n",
    "    The dataset may have a large number of features that may not all be relevant and significant. For a \n",
    "    certain type of data, such as genetics or textual, the number of features can be very large compared to \n",
    "    the number of data points.\n",
    "    \n",
    "\n",
    "6. *Supervised or Unsupervised learning (Supervised in this case)*\n",
    "\n",
    "   Supervised learning algorithms are used when the training data has output variables corresponding to the \n",
    "   input variables. The algorithm analyses the input data and learns a function to map the relationship \n",
    "   between the input and output variables.\n",
    "   \n",
    "   Unspervised learning algorithms are used when the training data does not have a response variable. Such \n",
    "   algorithms try to find the intrinsic pattern and hidden structures in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I am going to start with a Linear or Logistic regression algorithm and evaluate whether the data is non-linear.**  \n",
    "\n",
    "If non-linear, I will apply random forests (because they are easy to interpret).\n",
    "\n",
    "[The choice between Linear or Logistic regression, depends on what type of output I am expecting:](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "I am expecting to output a category (Logistic Regression): yes - heart disease or no - not heart disease.\n",
    "\n",
    "I am not expecting to output a quantity (Linear Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit my data to a logistic regression model\n",
    "\n",
    "[Instead of predicting exactly 0 or 1, logistic regression generates a probability—a value between 0 and 1, exclusive.](https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "heart_data = pd.read_csv(\"data/heart.csv\")\n",
    "\n",
    "#preview the columns\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data for the model by:**\n",
    "1. determining the target\n",
    "2. separating the features from the label \n",
    "3. splitting out the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determine the target (y) and separate label (y) from features (X)\n",
    "target = 'target'\n",
    "y = heart_data[target]\n",
    "X = heart_data.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data for model training, tuning, and evaluation**\n",
    "\n",
    "60% - train set\n",
    "\n",
    "20% - validation set\n",
    "\n",
    "20% - test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is applied to train, or fit, your model.\n",
    "\n",
    "The validation set is used for unbiased model evaluation during hyperparameter tuning.\n",
    "\n",
    "The test set is needed for an unbiased evaluation of the final model.\n",
    "\n",
    "In less complex cases, when you don’t have to tune hyperparameters, it’s okay to work with only the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the heart dataset into a Training Set and a Testing Set (testing set = = test_size = 20% of data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7, stratify=y)\n",
    "\n",
    "### Then split the Training Set, to set aside a Validation Set (validation set = test_size = 20% of data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=7, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_size:** is the number that defines the size of the training set. \n",
    "\n",
    "**test_size** is the number that defines the size of the test set.\n",
    "\n",
    "You should provide either train_size or test_size. \n",
    "\n",
    "If you provide a float, then it must be between 0.0 and 1.0 and will define the share of the dataset used.  If you provide an int, then it will represent the total number of the samples. \n",
    "\n",
    "The default value is None and then the default share of the dataset that will be used for testing is 0.25, or 25 percent.\n",
    "\n",
    "**random_state** is the object that controls randomization during splitting. \n",
    "\n",
    "Set any non-negative value, to make your tests reproducible. The default value is None.\n",
    "\n",
    "**Stratified splits** are desirable when you’re classifying an imbalanced dataset, a dataset with a significant difference in the number of samples that belong to distinct classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Train the model](https://realpython.com/train-test-split-python-data/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable called ml_model and use it to instantiate (call) the logistic regression classifer\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#fit the classifier to the training data - the training features and the training labels are passed in\n",
    "logreg_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Predictions Using the Validation Set**\n",
    "\n",
    "Reserve the Testing Set for evaluating predictions on the finalized Logistic Regression Model.\n",
    "\n",
    "Generate the first round(s) of evaluating model performance, using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predict command on the classifier and providing it with the parameters it needs to make predictions about\n",
    "#which are the features in your testing dataset\n",
    "log_predictions = logreg_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Evaluate the Predictions**](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Logistic Regression outputs predictions about test data points on a binary scale, zero or one.](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)\n",
    "\n",
    "If the value of something is 0.5 or above, it is classified as belonging to class 1, while below 0.5 if is classified as belonging to 0.\n",
    "\n",
    "Each of the features also has a label of only 0 or 1. \n",
    "\n",
    "Logistic regression is a linear classifier and therefore used when there is some sort of linear relationship between the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Score**\n",
    "\n",
    "Accuracy score is the simplest way to evaluate how the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8032786885245902\n"
     ]
    }
   ],
   "source": [
    "#pass in the predictions against the ground truth labels which were stored in the validation set labels\n",
    "print(accuracy_score(log_predictions, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, while it can give you a quick idea of how your classifier is performing, it is best used when the number of observations/examples in each class is roughly equivalent.\n",
    "\n",
    "Because this doesn't happen very often, other metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix and Classification Report**\n",
    "\n",
    "The Confusion Matrix and [Classification Report](https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn) give more details about performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  5]\n",
      " [ 7 28]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(log_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of correct predictions for each class run on the diagonal from top-left to bottom-right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78        28\n",
      "           1       0.80      0.85      0.82        33\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.80      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "f1-score is an average of precision and recall.\n",
    "\n",
    "The support is the number of occurence of the given class in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area Under ROC Curve (AUC)**\n",
    "\n",
    "This metric is only used binary classification problems. \n",
    "\n",
    "The area under the curve represents the model's ability to properly discriminate between negative and positive examples, between one class or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7992424242424243\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 1.0 = all of the area falls under the curve and this represents a perfect classifier. \n",
    "\n",
    "In contrast, an AUC of 0.5 is basically as good as randomly guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After fitting a basic Logistic model, the conclusion is that it is a fairly good predictor of heart disease (75%+ accuracy/precision).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Determine Feature Importance](https://www.kaggle.com/dansbecker/permutation-importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features have the biggest impact on predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the eli5 library\n",
    "\n",
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[eli5](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html) provides a way to compute feature importances for any black-box estimator by measuring how score decreases when a feature is not available.\n",
    "\n",
    "The method is also known as “permutation importance” or “Mean Decrease Accuracy (MDA)”.\n",
    "\n",
    "The idea is the following: feature importance can be measured by looking at how much any score we’re interested decreases when a feature is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this is another reference](https://medium.com/@lily_su/explaining-predictions-graphing-feature-importances-permutation-importances-with-eli5-partial-839b58eee962)\n",
    "\n",
    "[and a third reference](https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0754\n",
       "                \n",
       "                    &plusmn; 0.0491\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0525\n",
       "                \n",
       "                    &plusmn; 0.0382\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0492\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0814\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0359\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0066\n",
       "                \n",
       "                    &plusmn; 0.0491\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(logreg_model, random_state=1).fit(X_val, y_val)\n",
    "log_feat_importance = eli5.show_weights(perm, feature_names = X_val.columns.tolist())\n",
    "log_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is showing the most important features (in green, from top to bottom) and the features that are less predictive (in pink).\n",
    "\n",
    "The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric).\n",
    "\n",
    "You'll occasionally see negative values for permutation importances.  This happens when the feature didn't matter (should have had an importance close to 0), but random chance caused the predictions on shuffled data to be more accurate. This is more common with small datasets, like the one in this example, because there is more room for luck/chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Examine the Learning Curve](https://vitalflux.com/learning-curves-explained-python-sklearn-example/)**\n",
    "\n",
    "[A learning curve](https://realpython.com/train-test-split-python-data/), sometimes called a training curve, shows how the prediction score of training and validation sets depends on the number of training samples. It plots the optimal value of a model's loss function for a training set against this loss function evaluated on a validation data set. \n",
    "\n",
    "You can use learning_curve() to get this dependency, which can help you find out how much a machine learning model benefits from adding more training data and whether the estimator suffers more from a variance or bias error.  If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABjXElEQVR4nO2dd5xVxfn/38/t2wsLSxUWBQRUQBBUuiViiYixofgVjRpjjKJff8bERqJGE/0m0WgwGHtUYsOgQbEuYGx0pYMsvW9j2+3z+2Nu22XL3WXvNubt63jvnTPnnOeevcznPPPMPCNKKQwGg8FgaAyW1jbAYDAYDO0PIx4Gg8FgaDRGPAwGg8HQaIx4GAwGg6HRGPEwGAwGQ6Mx4mEwGAyGRmPEw2BoAiIyVkQ2tLYdBkNrYcTD0O4Qka0iclZr2qCUWqyUGpCo84vIOSKySETKROSAiCwUkQsTdT2DobEY8TAYakFErK147UuAN4GXgZ5ALnA/8OMmnEtExPw7NzQ75kdl6DCIiEVE7haRH0SkUETeEJHsmP1visheESkNPdUPjtn3oojMEpH5IlIBTAx5OHeKyHehY/4lIq5Q/QkisjPm+DrrhvbfJSJ7RGS3iFwvIkpEjqvlOwjwJ+BBpdQ/lFKlSqmgUmqhUuqGUJ2ZIvLPmGP6hM5nC33OF5GHReS/QCXw/0RkaY3r3C4i80LvnSLyuIhsF5F9IvKMiCQd4Z/D0MEx4mHoSPwSuAgYD3QHioGnY/Z/APQDugDLgVdrHH8l8DCQBnwRKrsMmATkAScB0+u5fq11RWQScAdwFnAcMKGecwwAegFv1VMnHq4GbkR/l2eAASLSL2b/lcBrofePAv2BoSH7eqA9HYOhTox4GDoSNwH3KKV2KqU8wEzgkvATuVLqeaVUWcy+ISKSEXP8v5VS/w096btDZU8qpXYrpYqA99ANbF3UVfcy4AWl1BqlVGXo2nXRKfS6J76vXCcvhq7nV0qVAv8GpgKEROR4YF7I07kRuF0pVaSUKgN+D1xxhNc3dHCMeBg6Er2BuSJSIiIlwDogAOSKiFVEHg11aR0CtoaOyYk5fkct59wb874SSK3n+nXV7V7j3LVdJ0xh6LVbPXXioeY1XiMkHmiv492QkHUGkoFlMfftw1C5wVAnRjwMHYkdwLlKqcyYzaWU2oVuMCeju44ygD6hYyTm+ESlmN6DDnyH6VVP3Q3o7/GTeupUoBv8MF1rqVPzu3wMdBaRoWgRCXdZHQSqgMEx9yxDKVWfSBoMRjwM7Ra7iLhiNhu6b/9hEekNICKdRWRyqH4a4EE/2Seju2ZaijeAa0VkoIgkA/fVVVHpNRLuAO4TkWtFJD00EGCMiMwOVVsJjBORY0Ldbr9uyACllA89gusxIBstJiilgsCzwJ9FpAuAiPQQkXOa+mUNRwdGPAztlfnoJ+bwNhN4ApgHfCQiZcDXwKhQ/ZeBbcAuYG1oX4uglPoAeBL4HNgcc21PHfXfAi4HrgN2A/uAh9BxC5RSHwP/Ar4DlgHvx2nKa2jP602llD+m/Fdhu0Jdep+gA/cGQ52IWQzKYGhZRGQgsBpw1mjEDYZ2g/E8DIYWQESmhOZTZAF/AN4zwmFozxjxMBhahp8B+4Ef0CPAft665hgMR4bptjIYDAZDozGeh8FgMBgaja21DWgucnJyVJ8+fZr9vBUVFaSkpDT7eZsDY1vjaat2gbGtqRjbGk+sXcuWLTuolGr8pFClVIfYhg8frhLB559/npDzNgfGtsbTVu1SytjWVIxtjSfWLmCpakKba7qtDAaDwdBojHgYDAaDodEY8TAYDAZDozHiYTAYDIZGY8TDYDAYDI3GiIfBYDAYGo0RD4PBYDA0GiMeBoPBYGg0RjwAjwcKCxuuZzAYDAaNEQ/A64UtW8Dtbm1LDAaDoX1gxCNERQVs397aVhgMBkP7IGHiISLPi8h+EVldx34RkSdFZLOIfCciJ8fsu0ZENoW2axJlYyxJSbrrqrS0Ja5mMBgM7ZtEeh4vApPq2X8u0C+03QjMAhCRbOAB9NrTI4EHQquvJRQRSE2FggIIBhN9NYPBYGjfJEw8lFKLgKJ6qkwGXg4ldvwayBSRbsA5wMdKqSKlVDHwMfWLULPhdOrg+b59LXE1g8FgaL8kdCVBEekDvK+UOqGWfe8Djyqlvgh9/hT4FTABcCmlHgqV3wdUKaUer+UcN6K9FnJzc4fPmTOn0TYGAvD1151Yvz6Vfv3KGT68EBHdjSUC5eXlpKamNvq8LYGxrfG0VbvA2NZUjG2NJ9auiRMnLlNKjWj0SZqSxz3eDegDrK5j3/vAmJjPnwIjgDuBe2PK7wPubOhaTVnPw+9X6swzlUpJUUpEqeRkpU47Tamvv1Zq06bD8963NYxtjaet2qWUsa2pGNsaT3tfz2MX0Cvmc89QWV3lzc4HH8DXX+uRVkpBZSWsWgUrV8KBA1BWloirGgwGQ/unNcVjHvA/oVFXpwKlSqk9wALgRyKSFQqU/yhU1uysWKEFI5aqKli3DlJS9NwPg8FgMBxOwtYwF5HX0fGLHBHZiR5BZQdQSj0DzAfOAzYDlcC1oX1FIvIgsCR0qt8ppeoLvDeZYcO0SJSXR8uSkmDgQHC5oLgY/P5EXNlgMBjaNwkTD6XU1Ab2K+AXdex7Hng+EXbFcu65MGpUtOtKBE48EcaN0/vT0vTcD68XHI5EW2MwGAzth6N6hrnVCgsWwPPPwwUX6LjHaafpcgBbSFp37mw9Gw0Gg6EtkjDPo71gtWoPpE8fHe+YPRsuuQQ6d47u37cPunTRkwgNBoPBcJR7HjW56y7w+eCJJ6qXJyfD1q3aMzEYDAaDEY9q9OkDV10Fb70F69dHy5OSdFDdpG03GAwGjRGPGtx8M2RkwCOPVPc00tN13iufr/VsMxgMhraCEY8aZGTAL3+pR2B99lm0PBw83727dewyGAyGtoQRD3RQPDaT7uWXQ9++8Ic/gM8nkfL0dC0eFRWtYKTBYDC0IYx4oAPi2dnRyYJ2O9x9N2zbBu+91yNSL5wwcds2Ezw3GAxHN0Y8QvTsqdOxh0Vh3DgYMwZee603xcXResnJesGoooTMeTcYDIb2gRGPEMnJ0LVrNBmiCPzqV1BZaeOpp6rXTU/XQ3dN6hKDwXC0YsQjhu7d9foe4fhH//5w3nm7ef11+OGHaD27XQvHnj2tY6fBYDC0NkY8YnA6oUcPOHQoWjZt2laSk3XwPJbMTNi1S89KNxgMhqMNIx41yM3VXVbhLqnMTB8//zksXAhffBGtJ6KTJZrgucFgOBox4lEDux2OOab6QlBXX63LHn20epwjNVWnbS8paXEzDQaDoVUx4lELOTlaRLxe/dnhgP/3/2DTJnjzzep109L0zPNAoOXtNBgMhtbCiEctWK3Qu3f1RaLOPhtGjoQnn6zulTgcOmXJ3r0tb6fBYDC0FkY86iA7Ww/fDY+8EtETB4uLYdas6nUzMvSaH253y9tpMBgMrYERjzoQ0Vl2Y9OWDB4MU6bAyy/D9u3RcotFd3PFlhkMBkNHxohHPaSn6y6s2FxWM2ZooXjssep1U1N1yvbS0hY10WAwGFoFIx4N4HDo7qjwcNzcXLj+evjoI/j22+p1TfDcYDAcLRjxaACLRS9JGxs8v+466NZND92N7dZyOPQIrf37W95Og8FgaEmMeMRBz556fkfY+0hKgv/9X1izBt59t3rdtDQd+/B4WtxMg8FgaDESKh4iMklENojIZhG5u5b9vUXkUxH5TkTyRaRnzL6AiKwMbfMSaWdDuFza04hNW3LBBTBkCPzpT9VjIlarXjhqx46Wt9NgMBhaioSJh4hYgaeBc4FBwFQRGVSj2uPAy0qpk4DfAY/E7KtSSg0NbRcmys546dZNex7heIYI/PrXcOAA/OMf1eumpenyWLExGAyGjkQiPY+RwGal1BallBeYA0yuUWcQEF7s9fNa9rcZ7Hbo1au6IAwbBuefD88/f3iG3dRUHTyPjYkYDAZDR0FUgrL6icglwCSl1PWhz1cDo5RSt8TUeQ34Rin1hIhcDLwN5CilCkXED6wE/MCjSql3a7nGjcCNALm5ucPnzJnT7N+jvLyc1NTUyOfKSh1El9DqtPv2ObnhhpGMHn2QX/1qXbVj/X6dqTe8/nmibWtLtFXb2qpdYGxrKsa2xhNr18SJE5cppUY0+iRKqYRswCXAP2I+Xw08VaNOd+AdYAXwBLATyAzt6xF67QtsBY6t73rDhw9XieDzzz+v9vnAAaW++kqpDRui2003KQVKvflm9fK1a5X65hulPJ6EmHaYbW2JtmpbW7VLKWNbUzG2NZ5Yu4ClqgltfCK7rXYBvWI+9wyVRVBK7VZKXayUGgbcEyorCb3uCr1uAfKBYQm0NW6ys/Voq9jRVDfcoIfz/v731dOzW63aQ9m5s+XtNBgMhkSSSPFYAvQTkTwRcQBXANVGTYlIjoiEbfg18HyoPEtEnOE6wGhgbQJtjRuLRactiZ33kZoKt90GK1bA/PnV66en63kfsfUNBoOhvZMw8VBK+YFbgAXAOuANpdQaEfmdiIRHT00ANojIRiAXeDhUPhBYKiKr0IH0R5VSbUI8QAtCRkb1VQQvvhgGDoTHH6+eIFFEeyoFBWbRKIPB0HFIUChXo5SaD8yvUXZ/zPu3gLdqOe5L4MRE2nYkiOjFob7/XgsD6C6qu++Ga66BF1+Em26K1k9KgqIiOHhQd28ZDAbDkaKUwhf04fF7CKgAma7MFr1+QsWjI5OaCp066e6o8GCKU0+Fs86Cv/8dfvKT6kKRng5bt+q1z+321rDYYDC0V3wBH96AF0/AQ7mnnHJfORXeCh28RndpjOwxEgkPA20BjHgcAb16wXff6e6o8N/srrv03I+//AUefjhaNzxcd+dOyMtrcVMNBkM7IBAM4Al48Pg9VPoqKfeWU+4txx/0IyIopbBb7dgtdtKd6RGxKHYXt7itRjyOgKQk6NJFp2JPT9dlvXvDtGm662raNB0HCZOeDvv26WNSUlrFZIPB0AYIqqD2JPweqvxVlHnKqPBW4AnoYZyCYLFYcFgdJNuTsVqsrWzx4RjxOEJ69NCpSIJBPRIL4OabYe5ceOQReOmlqFciovNkbd0KgwZFyw0GQ8fF4/dEvIkyTxnlvnKqfFUIgkJhEQt2qx2HzUGyI7m1zY0bIx5HiMOhs+7u3KnjGaA9jFtvhd/9Dj79VMdBwiQn6+B5UZGOmRgMho6BN+DFG/Di9rmp8FVQ5imj0lfJyr0rI11ODqsDh9VBVlJWa5t7xBjxaAa6dIHdu3U6knBs4/LL4dVX4Y9/hHHjtMiESUvT3kdGRuJSlxgMhuYnPMIpLBSVvkrtTXjLUUQyZ2hPwurAKtYOIRS1YZquZsBm00N3t2zRM9DDZb/6Fdx4I7z2GkyfHq1vt+s07rt36+MMBkPbIqiCkRFObr/2JCq8FVT6KiOjmxQKm9hwWB2kOdOwSC3T5jpw17QRj2YiJwd27dIrCYa9jPHjYcwYePppmDwZsmIeQDIytHjk5OiuLIPB0PIEgoFod5PfTbm3nApfBVV+HZMAQIHNqkUidoTT0Y4Rj2bCYtEjrTZujHofoCcOTp4MTz0F990XLRfRGXe3bYPjjzfBc4MhkYS9iHBXU9iT8Aa8kToigsPqwG6xk+nMNCLRAEY8mpGsLD0E1+3Wo6oA+vXT8Y/XX4epU+G446L1U1L0MN/i4uqCYzAYGo9SKiIQHr+HCl9FZK5EUEUX1rFarNgtdpw2JykOM2a+qRjxaEZEdNLE1auj4gHwy1/Ce+/BH/4Azz5b/Zhw8Dw93QTPDYZ4UErhCXgiI5u8AS/f7/ueKn8VoXAEiuhkujrjEYYjwjRXzUxamvYiYtOWZGfruR9/+AMsXgxjx0brOxx6gam9e/WQX4PBcDhhT6KoqogSdwmBYEDHJETHLUSEDGeG6WpqQYx4JIBevWDVKt0tFf4tT5umu64efRROO626l5GeroPtOTnVPRaD4WjFF/BR6aukxF1CUVVRJDbhsDpIdaRW8ySKLcU4rI66TmVIEMaXSwDJyZCbC2Vl0TKHQ+e92rwZ3nijen2LRQ/f3batZe00GNoKgWCAMk8Zuw/t5vt937N8z3LWH1xPYVUhTpuTrKQsspKySHGkmC6oNoLxPBJEjx46BXts2pKzzoKRI+HJJ+GCC6L5sEB3cYWD51kdc06RwRBBKUWVv4pybzmFlYUc8hwCwCIWkuxJHXZiXUfCiEeCcDqhe3c9lyOctkQEfv1rvXDUrFl6EmEsaWmwfr1+7dRJvyYl6bVCDIb2jtvvpsJbQbG7uFrcwmV3kekyQ2PbG0Y8EkhuLuzZUz1tyaBBMGUKvPKKHrobO8Pc4dCi4fXqXFnBoBacjAwddE9J0WJi/o0Z2gPhuEWxu5jiquJI3MJpcx4WtzC0P4x4JBC7XYvDtm1R7wPg9tvhww/hscfgr389/DiHIzpLXSk9b2TLFv3ZatXdWtnZZllbQ9siEAxQ6avkkOcQhVWFVPn0Os12qx2XzWXmVHQwjHgkmNrSlnTpAjfcAE88Ad9+q+MgdRFeAz283G0gAIcO6fhIZSWsXKmFJCNDB+rNKoUdl3DSvbbSvROOW5R5yiiqKorELawWKy6by8QtOjgNioeILAOeB15TSrX8clXtHKtVpy3ZtKn6LPLrrtOjrh55BN56K/64htUaXUiquFiLxYEDunsMtIDk5Jh4SXtBKUVABfAH/QRVkFJ3Kf6gP5JrKbz0qMfvIUgwMgnOKlasFisWsSAiWLBgsViwYImU17aFjxMRBDnsNXy+mvtAexa+oI8Kb3S+RVAFTdziKCUez+Ny4FpgiYgsBV4APlLKdJrES3a2bsg9Hh1IBz2f48474X//F959V6953hTs9ureRmy8BHR3mYmXtDyBoBaEsDD4g358AV9UEPwendo76AWlV46r8lexoXADQRXEZrFFGnqrWKvNkg6vW13zNaiC+JUfFaheHj4mqILV0oYjIEpPtKvm1Si9L/a1wlfB0t1LI8c5rU4zc/sop0HxUEptBu4RkfuAC9BeSEBEXgCeUEoVJdjGdk84bcnatVHxAL3W+SuvwJ//DJMmNc/StA3FSzIzdVA+Obm6LW2BYFB3y4Vfbbbq66C0NkEV1IIQIwyxabsjeZVCS4lGGuSYFePCYhDu2kmxRP/oxZZiMl2ZDdoR9ghaMt13saXYdEMZqhFXzENETkJ7H+cBbwOvAmOAz4Ch9Rw3CXgCsAL/UEo9WmN/b7QYdQaKgGlKqZ2hfdcA94aqPqSUeinub9UGycjQDXdlZTQFe3jo7uWX65xXM2Y07zVrxkuCQT1xsahIC4vT2fzxEqX0dcLCFQhUFwSvV48+83rB59Pvw69hbynsHQWD2r6uXfU8GEsLP+R6/B6Kqoo4WHkQj99DQAVC9ulV4cINeKyHEA4Om+4bQ0cn3phHCfAccLdSyhPa9Y2IjK7nOCvwNHA2sBPd7TVPKbU2ptrjwMtKqZdE5AzgEeBqEckGHgBGoJ3nZaFj23XM5Zhj4LvvqncfDR2qJww+95xOa7J3rx7OO25c88crLJbq3o3frycyxsZLOnXSkxfDaVJqNv7BYLTxr0sERKCqSqdoEdFCEn61WPT3sliim8ulX2trbysrtcfmcEC3blpMEukxBVWQMk8Ze8v3UlxVjEUsJDuSSXWaoaUGQyzxeB6XKqW21LZDKXVxPceNBDaHjxWROcBkIFY8BgF3hN5/Drwben8O8HG4S0xEPgYmAa/HYW+bJSUFOneG0lId0A4zYwb85z96vY9gUIvLkCFaUBIZ8LbZoskbQQvBrl2wY0f1hjzc+Me+t1qjr2FBcDii3kFzzZRPTtab36/t2rYtMd6I2++mqLKI3eW78Qf8uOwuspNNnnyDoS7iEY/rReSPSqkSABHJAv5XKXVv/YfRA9gR83knMKpGnVXAxeiurSlAmoh0quPYHjUvICI3AjcC5Obmkp+fH8fXaRzl5eXNel6l9NP0wYPRsm++6YTVOhi/X7eElZWwbFmAP/5xG8OGFeN0BnC5grhcAZzOIE5nAIsFPJ5yCgqazzbQ3sXSpZ3YvDmV444rZ8SIwiYJWCJsC1NcrEevieiuNpst/oEANf+e4bhFQAWqjTYqpTQhtteHp9JDwcqCFr9uPBjbmkZL2eYP+lm4aWHc9ZujXYtHPM5VSv0m/EEpVSwi5xGNRxwJdwJPich0YBGwCwjEe7BSajYwG2DEiBFqwoQJzWBSdfLz82nu827bBvv361gDwPz5utGOxeu18uKLfXnxxdrP4XKBw+EjNdWOy6W9leRkXZ6crD+H39e2v7Yyu12PAFuzRnc7HYkHVFCQT17ehEbemcbh9+vU942JjeTn5zNq9CgKqwrZU7aHgAqQZEsiyZ6UUFvjoWBlAXlD81rbjFoxtjWNlrKt2F3MyO4j4461NUe7Fo94WEXEGY51iEgSEE+v8y6gV8znnqGyCEqp3WjPAxFJBX6ilCoRkV3AhBrH5sdxzXZBt26wb58WDKtVxziSkrTHEcbp1GuAHH+8bshr2/bt24/d3qNaWUmJjmHUrNsUKith+XL4+GM9GqytYbNFZ+43FBsJBAOUuktx+92s2rsKq8VKqiMVq8VMhDEYmkI84vEq8GloaC7oUVfxjHxaAvQTkTy0aFwBXBlbQURygCKlVBD4NXrkFcAC4PehLjKAH4X2dwgcDh0c375dxwXGjdNP+KtWVX/iv+GG+p/4Cwo2kZd3WG/eYYRHPtUlQuHtww+hpifr8eh0Km+8oe0cNw7y8trefJG6YiNp2ZV4rAfZX7k3Mu/BxDIMhiMnnnkefxCR74AzQ0UPKqUWxHGcX0RuQQuBFXheKbVGRH4HLFVKzUN7F4+IiEJ3W/0idGyRiDyIFiCA33W0+SRduuiMuz6f7i567jlYtAjWrYOBA5t3tFXNIbt1kZmp06XU9IDGjtVzRR55RG+9emn7xo/XqVUaOm9LYrNBarqfMm8pq/bspnRLBS67jWO6pZOdZaFESlrbRIOhQxDXPA+l1AfAB409uVJqPjC/Rtn9Me/fAt6q49jniXoiHY5w2pIfftDeh9UKEyfqrbWoywN68klt344dWuAWL4a334ZXX9XiMnJkVEx6924d25VSVPorKHIfoNhzAIXC5UomPSWbQAD274O9e8Dl0XNdUlJaft6IwdCRiGeex6nAX4GBgAPtRVQopdLrPdDQINnZhydNbE2sVpg9Gz7/XHtAJ52kBSHsAfXqBVddpTePB5YsgYULtaA8/LDeevfWQjJgQDbduiV+WV1f0EeZt4T9Vbtx+6uwWRyk2NOrzcmwWqNDo917tWDb7XrYdGZm27j3BkN7Ix7P4yl0vOJN9KS9/wH6J9KoowWLRU8cXL9eT85rabze6CS/MDYbnHMOnHeeTrjo89XefeZ0wpgxervnHh2/WbRIb2+8AR7PSTz0EIwapQVo3DgtPs2BUooKfzlF7v0UewoBhcuaQoaz4ViGWPQot0BAT8jcvVt/zskx3ojB0Bji7bbaLCJWpVQAeEFEVtCBAtitSWambrzC3USJIBiMCkU4BYhSOsCcna2Ht7pcWhBiU5Tk5uqn9OJibWN9Desxx8C0aXpzu+G9975jw4aTWLhQeyegA+3h7q1TTmn8E7834OWQt5gDVXvwBj3YLHbS7BlNSgVSzRtxG2/EYGgs8YhHpYg4gJUi8kdgD2Cez5oJEf1Evnp184iHz3e4N2G1aoHIyYkmRHQ6DxcDf9BPqbuCwspCit06NYd0sVBRaGXrLhsuh5W0FBtW0ZvNYkPC6b6xRN/bLAwfXsjki73c/RsL27dZ+GKxhYUL4fXX4aWX9Hc99dToCK6ePaN2BALag1m7FgYOVAw/vYwS3z6KPUU6+G9NId2WfOQ3K4TLpTfjjRgM8ROPeFyNFotbgNvRczeamEDcUBvhNcvLy6unC6mPYDCa6DA8wVAp3QhmZOhzhr2J+p6i3X435Z5yDlQeoMxbRlAFcVgdJNt14xxUQbp0UaSl+dixy8POg0GSUxRiCaJUUK8xgWARiaxsKALWQBVri1foz2kw5Dw4+QIbfredNcvTWf51Okv/m8rnn2vjeuf5OH2sl1NP9/Pyc8msXWPDXQVOV5DjBilmPlFOuiOx60XU541kZ0eXEjYYDA2IRyi54e+VUlcBbuC3LWLVUUivXnqUU2weqTDhBIReb7RMRG+5ufrpOOxNNDS8N6iCeqlQ9yEOVB7A7XeDQJItiQzn4V1AVvQJHamQ3l9n5N21CyzWaHbg2vBIMcmO6smtgiqISg5yyphyRowu46d3BNm9zcHSL9NY/lU6b76eyusvW4guJAHuKiub16ax5tsujBpbUf+Xa0ZivZE9e/Skzm7doiPjDIajnXrFQykVEJHeIuJQSnnrq2s4MpKStBDs26c9hXC3k4gWhbS0aLbbcGxi4cLq3T114Q/6KfeWU1RZRJG7iEAwgEUsJNmTGrVGg4j2kNLS9IJTJSXaU4r3idwiFhALsW3vscfCscdWcvnVlVRVCk8+ksvnH6ZVO85dJWxY62xR8Qhjter7Hgho0dy7V4tIZqYREcPRTTz/7LcA/xWReUDkX69S6k8Js+oopUcP7WW4XLpRjtebqA23302Zp4yDlQcp85ahlMJutZPqOPLU4g6HDn6Xluq5H6C9nyPtUUpKVkz4URlfLUzFXRV7MmHua1mooPDjS0vIzok7/VmzESsiO3dqEeneveGBBAZDRyUe8fghtFmAtAbqGo4AhwP69WvaseHuqFJ3KQcqDkRWs0uy194ddaSI6KfvlBTdrVNYqN8f6YJSI06v4PgTqli/OgmPW3C6FD17e+mc62fOC9m89UoWEyeVMeXKYvKOa3lnOCwifr9OgRLOpWVExHC0EU96EhPnaMOUuEsoqiyisKqQoArqxYvsySQ7mm80Un3Y7XqYblaWnutRVVV9rZLGYrXCw3/dxdIvU/hho5Nj+3sYcXoFVivs2m7n3TlZfPReOh+9l8HJoyq4+Mpihp9W2eK5tmw2LRg+nxYRpzMqIm0t75ehY+P1gruJyU+PhHhmmH+OjmBWQyl1RkIsMtRLbHdUha+CDQc3YLfaSXOmtepKd2lpMGCAjtns3w+uw34x8WO1wqixFYfFOHoc4+MXd+3nf352kPlzM5j3Rhb33taTY/I8TLmymDPPLcPhPIILNwG7PSoiW7fqLsdu3bR3YkTE0JzEzteqqoLyCqgo14NsKgIwtm/L/ubi6ba6M+a9Cz1M158Ycww1CXdHlbhLOFhxELffjYiQZE/CZrE1KuCdaGw2HbfJzITt34dySKWCpZl/0GkZQS6fXszFVxWz8OM05r6axRMPd+XFv+Xw40tLuOAnpWRmt2xcJFZECgq0iPTooWNXRkSal/A8Jput4w6f9vt1CiCvFyoq9OZ2R/dbLPo3F/73VVbY8jbG0221rEbRf0Xk2wTZYwB8AR8VvgoOVh6kuKqYoApitVhJsiW1WHfUkRAeOpydq+MhTmdiclzZ7XDWeWWceW4Z3y1L4u1Xs/jn7Bz+9WI2Z513iIumltC7b8vGRcIi4vXC5s16OHOPHs0zoOBoJRCAKjeUl+kRfh5P9f32Kn2vw78zh0OLSniVybYci1IqOrHX7dZzvSortXiE94e/S1pa2/oNxdNtFZswyAIMBzISZtFRilKKQ55D7C7bzSHPIQAcVkerd0c1lfAclPR0PTopvG57Iv4hi8CQEVUMGVHFjq125r6exSf/SeeDdzM55fQKplxZzLCRLRsXcTj05vHoJXPT0qBrN0hNaTkb2jMej25Ei4u1Bwv6t+Ny6d9Utbru6ITZ4mIik1XD2O3RkYux4hJulFvqdxEIRLudKiu1N1FZSbXJtQ6HtrMtLXNQF/E4fcuIztryAwXATxNp1NFGmaeMHaU7OOQ51Oi5F22dpCQ47rjo5EJrA5MLj5RefXzc+uv9XPPzg7z/VibvvZnJb27pSV4/DxdfWcxpwySuZTCbi3Cj5fHApo1aRLp1056IIYrfr5+8Dx3S3kV4nlN4jlNDDbzdXvdIv2Awev6iouqNtVIhoXeCK9Rohz2W8NYUcfF6wevT192+XYtErMdkterrtOduzXi6rdrm4sAdgHJvOTsP7aS4qphke3KHXeHuSCcXNoWMzCBXXV/EpVcXk78gjXdey+L/ftuVrKwsLryijPMvLiE9M5g4A2oQFhG3GzZuhPQM6NY1sULallGqundRXq5/J2HvojmfvC2WqCdYG4EA+EIjlg4erN6YK1Xda3G5ouJiterN59Pfpaoq6k2EUwbZvOAr18fU9JjaO/F0W/0CeFUpVRL6nAVMVUr9LcG2dVgqvBXsOrSLwqpCkuxJdEpuhXzsrUB4cmFJiZ5cKBJ/Lq8mX9Op+NGFhzj7x4dY/k0yb73g4qVZOcx5PpuzLzjERVOL6dnb1/CJmolwA1RVpUUkI0N37x0NIuLzafEsLdW/gXADG693kSjCIlAbSmk7w0Ln90ftjPVgwq92OyQlRweJeNzgbAddUE0hnme/G5RST4c/KKWKReQGwIhHI6nyVbGzbCeFFYU4bI6jRjRiEdFzQsKTC4uKmmdyYTzXHX5qJSf0XcOeQwN45/UsFsxL5/23Mxk1tpyLryrmpJOrWqwBCy8LXFmpRSQzM5ouv6OglBbJsHcRXt7YZtPfvS0HssOItO1RXYEALP0yhRUrksjxwPnnt1zanHhuiVVERCmts6FkiWa1g0bg9rvZdWgXByoP4LA6Omz3VGNwOPSqg9nZuk/Y7W65/t8+x3m54759XHuzjou8/1YGv7qpF8cd7+biK4sZd3YZNlv0H+bmDU6OGxCdrNicJCeHxulXAG59L7p0SfwKjIkiPAchHLsIBqP52Tpat01rEwjAPb/sEcnG8MlcvfjaggUtIyDxiMeHwL9E5O+hzz8LlRkawOP3sKd8D3vL9mK32slyZSU0pXh7pObkwqQk3dC0BFmdAlz9s0Iuu6aIT+enM/f1TP54fzeefyqHCy4pYelXKWxe74qkSTn+hCoe/uuuZv+HKaJFxFOuG92iIuiUA106t9y9aCrBYGjCWrkWi/BcBLsdklOaf46PIcpX+ams+z4Jj1u7cOXl8M038MEHcMEFib9+POLxK+BG4Oehzx8D/0iYRR0Ab8DLvvJ97C7bjUUsZCUZ0aiP2MmFO3YkbnJhXThdivMuLmXSRaUs/SqFd/6ZxYt/60z11PDC+tVJLP0yJaHZfVNStCdSUgxFhXpBqs6d29bKhuGJa6WlWuzCywjUNoy2uanNG+yoKAUlRVb27LKzZ6edvbvs7NllZ+9uO3t2Oig8cHjzXVEBK1e2HfFIAp5VSj0DkW4rJ1CZSMPaI76Aj30VWjQEIcOV0S7naLQWKSk6MeTBgzoe4nC07Hh3iwVGjq5g5OgKnnq0C++/XX06k7tKWPZ1csJTw4cHEiilE04ePKgFpFOnw0cChV/DW+QzRJIK1bo/5n14YbFwWfgzQFCBCoLXo9OvuN3RIacOR8uKfM1umrA3eP99BS1jQALweoV9u23s2eWIikNILPbsske8CgARRafOfrr18DH81Ar8flj8aRo+b7ROSgoMHdoytscjHp8CZwHloc9JwEfA6Q0dKCKTgCcAK/APpdSjNfYfA7wEZIbq3K2Umi8ifYB1wIZQ1a+VUjfFYWur4A/6OVBxgB2HdoCCdFe6EY0mYrVGJxfu2aOfbltaRABOGV3BJ/PTa6SGh3lvZLFqaTLjzipj3Nll9OqTuJFaIrpbL6i0gBw4cLh4xPu55sS58L7Y+uHPtZUR1MIRzirckpSXWdi41sWn89P4blkywWDUG/xuWTK/uWskx/S3kJoaICUtSGpakJS0ACkp0fepaUFSUoMkJQebJVAfbzxMe5HW6p5DjDgUHrChVPSGO11BuvXw0bWHj2GjKiPvu/XwktvNXy13WyAARQdtETFNSYFRo4Rzzz3y7xcP8YiHSykVFg6UUuUi0uDAwpCH8jRwNrATWCIi85RSa2Oq3Qu8oZSaJSKDgPlAn9C+H5RSQ+P7Gq1DIBjgYOVBdpTuIECAdEc6VotZIag5SEqCvn31CJ19+3R/usPRckNaa0sNf+wAN2PPLOeLz1L557OdeGV2Dnn9PFpIziqjxzGJERKLHFmm4ubAY2mZ+IvbLfywwcnGNS42rnWxcZ2LXdtj++yqq2AwCHv2JHOwyEJ5mRV3Vf3KYLEoklOD1YUmNUhKaiAqNKnB0L4AKamh11C95JQgSh3uAeUd52HqdYXs2xMWCUeou6kv7qrqzWynzn669vAy9JRYcfDRraePzOxA3INGYjNQr1gZ5Nqf9Gxzo60qRORkpdRyABEZDsSTAHgksFkptSV03BxgMhArHgoIP8dkALvjNbw1CapgVDSCAVKdqdgsbXQsXzsnOVnPDQmLSGlpaCx9UmJHZtWXGv6iK0o4uN/GF5+lsujjNF6alcNLs3I4doA7JCTldOvZcnNH2it+PxRsdmqRCG3btjgIBvQftlNnP/0HuTnr/EP0H+SmrNTCXx7uWs0bdCUpfjljDWMuSI2cs6LcQkW5lYoyC+Vl+n15mYWKstBreUxZuYXdO+1UlDmpKLdQWVF/yyuicDiDeDwWUFEPaN33Sdx/u17W0+EM0rW7FoQTBu2lx3FJEZHo2t2H80hSTtcgnIG656BiLji7Z4sOfxZV05+tWUHkFGAOumEXoCtweS0JE2sedwkwSSl1fejz1cAopdQtMXW6obvAsoAU4Cyl1LJQt9UaYCNwCLhXKbW4lmvciA7mk5ubO3zOnDnxfOdGUV5eTmrMTLZAMIAn4EGhsIq1VQPhnkoPzuS2ORwnUbYFg3qyWSAQnZHcGJTfg9ia164DB1x8+UUuXyzuysYNmQAc16+U0WP3MnrMXnJz3fWfIIG2NRdHalswCLt2prBpUwabN6azaVMGBVvS8Pl0Y52a6uO4/qX066e34/ofolOn6hkQAwGYed8INm7IwOOx4nQG6D+glAce+C+2ZnKLAgGhstJGRbmNykob5eV2Kipsegu9X7E8h40bMggPptAozj5nJ1dO20xWljfaXdhCf1Of30+n9Phz3sS2axMnTlymlBrR2Gs2KB4AImIHBoQ+blBKNfhYFad43BGy4f9E5DTgOeAEwA6kKqUKQ57Ou8BgpdShuq43YsQItXTp0ga/S2PJz89n/PjxFFcVs710O+6Am1RHKg5r6w9/KVhZQN7Qtpk9JtG2VVXpGEBRkR6tlZwcnyfi2V+As0vi7Nq728YXn6ax6JM0Nq7VkzWOP6GKsWeVMe7Mcjp3rXs1g0TbdiQ0xjalYP9eWzWPYtM6Z+Sp3ukK0m+gm/4D3fQf7KH/IDfdevji+vuFYw2x3qC/sGXv2zeLU3jknm7VushcSUF+/fCewwZTtNTfdFdhMdPPHoklztEL+fn5TJgwAQARaZJ4xNvXMgAYhF7P42QRQSn1cgPH7AJ6xXzuGSqL5afAJACl1Fci4gJylFL7AU+ofJmI/AD0B5pfHepBKUVABfhu/3dUeatIdaaS7TAT/NoCSUl6BcMuXfT8kOLiaNLF1hwV3bW7n0uuLuaSq4vZs9PO4k9TWfRJGs/+pQvP/qULg06qYtxZZYw5s5ycLu1nWZxAQDeatQWIS4qsbIgIhe6GKi3WTYvNpsjr5+GMSWX0H+Sm/yA3vfK8Te6Xr22hsJa+i7XFw44/oapVhw3/e8ezTGdki14zntxWDwAT0OIxHzgX+AJoSDyWAP1EJA8tGlcAV9aosx04E3hRRAaixemAiHQGipRSARHpC/QDtsT7pY4UpRRl3jK2lWzD7XdjwWJmhbdRXK6oiBw4CIUHdQPTFtbP6NbTx2XXFHPZNcXs2m5n8adpLPo4lWf+1IVn/tSFwUMrGX92OaPPKKNTTssuXtUYIt1FG7PwuAW7Qw8Z7dvPw6Z1Lvbv1bllRBS9+ng55fQK+g9yM2Cwh7x+HhyOll3dMdHUFw9rDVYc/Ip5u54Dnm3R68bjeVwCDAFWKKWuFZFc4J8NHaSU8ovILcAC9DDc55VSa0Tkd8BSpdQ84H+BZ0XkdnTwfLpSSonIOOB3IuIDgsBNSqmiJn3DRhJOj17qKSXFkYLNYsPZRvuhDVFcLujVU8/K3n9AT7CzWNqGiIBeQveKa4u44toidmy1s+iTNBZ/ksbfHuvCrMc7c8KwKkaf6mf8hVayOrW8kPj9UFJko7jISnGhjZJCa+T95g1O1n6fFBki6/UIe3Y6qKoUTjrZzYWXldB/kJvjjneTnNKxhKIu6loqORHsrdzJlkPr2VVRwK6Kbeyq2Eqlv4Knx87llY1/5dVNT2mbHtTdaA+Mf4CZE2Ym3K54xKNKKRUUEb+IpAP7qd4dVSdKqflobyW27P6Y92uB0bUc9zbwdjzXaC4qvBXsOLQjkh79aExa2BFwOqMicuCAnmQXnnTXFkQE9JojV11fxFXXF7Fti4NFn4Q8kr8NYvYzipNOrmLs2WWMnlhOZlagyTm26hKEkiIbRYX6tbjQSnGRjbLS2k+YlBzEagselrRRRHHhZaVc+dMWeabr0ARUgANVu9lZsZVd5VvZVbGV3ZXbmDliFjaLnXe2vMC8bfp5PdPRiR4pfTguYxBBFeTq/r/kx72v5IpPTidwXzDumEdzEI94LBWRTLRPtAw9WfCrRBrV0lR4K/h+3/c4bU4jGh0EpxN69gx1Zx3Qk+wsFj0Soy3Ru6+Xq28sZNoNhWxacoCvlh3Pok/S+OsjuTz9xy4MGV7Jwf02Duy14/GE5pv0d3PjHQc4VKxFISwIYZEoDgnDoXoEITPbT1Z2gF59vJx0chWZnfTnrE5+MrMDkfeuJKUDxL/Jxe2ONhfaDk+t5zccjlKKYs9BdlVs1SJRUcBP+l5HljOHd7a8wHPrH4vUTbal0CMlj0PeEjKdnTmv11WMz51MrrMPSdb0SDaAitDsO4tqnTYrnsWgbg69fUZEPgTSlVLfJdasliWoglgsFlIcZnm3jobDofNmde6sBaS4rOVzZ8WDCPTuU07/kYX8z02FFGzSHsmCeekUF0Ylz10lrFmVzG3X9K52fGMFoTGMOL2C/gNKIzGPthAgbiu8svGvXN3/l5HP5b5DWiDKCzghewSZwJL9C3lkxe1U+qP3y25xMDzrLBxpOQxKGcdN/TLolpRHt6Q+ZDo6ISIoL1QFoJurL/Z0sNv07zl2MSqLRb9ed+inLe5ZN2pmm1Jqa4LsMBgSisMB3buDey8kh0ZoQdsTEdBC0re/l779C7E7FK/M7hSZkKZRTDinjAsvK2myIDQGqxVmPriU7zef0CYCxM1BQzMUau5WSuEJVHHIV8IhTzGHfCV0TerJq5ueYlyXH/OX1b9mV+VWDvmi3Xg393+Es1KHkSa9GN/lYrol5dEjpTe9M/rQLa0bTocVhx26d+/PWGv/iBjYbFFRiFcQbjzlhsbdgGbATIs2HFWIBbp21euIFBXFiEhK21yc6LgBHlwuddis6onnlDHopPgmHzYHLRkgDhNee9zvj646GCa28bcFdHbfeFFKURkoQxEkzZ5JQAX4Yv97lPlKKPMVU+bXr8M7TWBi14sp8xVx41fj8Slvref72X/PAeC4jEFc1ft68jJ70yczj16ZvSjevIszT+jL2ZZ7GyUG7QEjHoajEodDi0inTlpE9u3TDVJqatsSkbY4p6C5CC/xGgjULhBWq57Pk5KiR9M5ndFV/WYt+yu/HKW7i7auBI7ZSmHlQUrcJRS7iylxl9A9rTvn9z8fgJ/++6fsKd9DsbuYUncpARXgkkGX8PAZD6OUhWmz7sEf9GMRC5muTDJdmaTmDOXEE8EXSON/qq4m05VJVlIWWa4sMl2ZHJNxDGNfGMuGWzZQF6WWtpVOvzmpUzxEpN6JDS01dNZgSCR2u87iG/ZE9u3T5W3FE2lrcwoaS33eA+iG1eWKLgJms+u+/XCffpgDFQf4eu9Klu9dzvf7vmfJ7iWsL1zH387/Gwj87P0b2Va6rdq5J/SeEBGPNGcaKY4ULQChxn9g54EAiAgfXvUh6c500pxph2XEtlvt3DX6rua9MR2A+jyPZcSuhlMdBfRNiEUGQysQFpGwJ7J3b9vxRFqjyyhelIoKg99/+DrsNpsWh9RULRDhYG94q60bJxAMsLFwIwUlBZzX7zwA7vjoDr7d9S0WLATRF/m04FMGPDWAq3pdxQPjHwCIeA2ZrkyS7dEUzH+Z9Jd6v0evjLhmHxzGLafc0nClDkqd4qGUaptJdgyGBGKz6eG9sZ5IIKAb8NhRLkcT4cWjKiurew/hNUHC66005D3Ux5r9a/ik4BNW7FnBqn2rqPRVYhUrE/tMJMmexG2jbsMqVgZ3GYzD6mDAUwMi3UUFKwvIO6Z1mqtw19nRSDzpSQS4CshTSj0YWsCpq1Lq24RbZzC0ErEiUlmpF0KqrNQJGStiHACR6k/T7ZmwF+Hz6VeIegZ2ID0DUpLj8x7qvoaioKSAlXtXsmLPCm4ddSudUzrz7a5veWbpMxyfczxTjp/CsK7DGNZtGC6bTi45onuj8/YZEkw8P/e/oVOEnAE8CJShZ3+fkkC7DIY2gc2mV86LXT0vENANrM+nl2StrIxusSv32WzRhrYtjbIJKvD7oqntIWpfcrJeSz45GewOcNj1d9i6Ss/cbyobDm7gz1//mRV7V1DiLgEgw5nBRQMvonNKZy4ZdAmXDb4s7rlWR3N3UVshHvEYpZQ6WURWACilikWkg44fMBgaxmrVm8tVfYW/8FojPh94vVBRCVWVUF4erRMWFZtNd+8kco5J2J7YYHV4DZSkZC2I4ThEeDsSkVNKsad8Dyv2rGDF3hUs37Ocq068ip8M+glOm5Ptpds5M+9MhnUbxsldTyYvKy8SnE5zNm6pxKO5u6itEI94+EJLyiqAUMbbYP2HGAxHH5bQUq3hdYmyQ+MVlQoJig98Xt31VVmp00uE4wZKgT2oPRm7vXFB+nCw2uuNzn8Qiaaoz8rSQhcrEs2BN+Cl1F1K55TOuP1uzvnnOewt3wtAki2Jk3JPiohCn8w+zL9qfn2nM7Qz4hGPJ4G5QBcReRidZffehFplMHQgwkFlhwNI0Y15mLCn4vPBvo1gc2hx8ccsUmGxRAUl3GUWO0kuHLDOzq4uEs0dgymsLOShRQ/RPb07K/asYPX+1Zze63SeueAZXDYXk46dRK+MXgzrOowBOQPM0swdnHhyW70qIsvQ624IcJFSal3CLTMYjgJiPYEiO+SFBsCHA9c+XzRY7/FoTyIlRXs34WObMvrLH/RT4i7hkOcQfbP0RfO35rN6/2oKqwopqiqiqKoIl83Fsz/W60Tc8dEdfL3za+wWO4M7D2bqCVM5rddpkXP+euyvj+heGNoX8U4S3A+8HrvPTBI0GBJHOC6SlBQN1v/1m7/W29df6i5lT/meSMNfWFVIcVUxt466FYtYmL1sNu+se4fiqmJKPaUoFC6bi1U3rQJg/qb5/HvDv8l06pnU2UnZZLm0m/TKtlf4eufXAPiCPlbuW8mYY8Ywoc+EhN4HQ9sl3kmCxwDFofeZ6BUAzTwQgyHBVPoqcVgd2Cw2nlryFN6AlyK3FofiqmKKqop4/Sev0ym5Ey+teomnlzxd7XiLWLh26LVkuDLIcmXRv1N/spOyq21BFcQiFmZOmMnvz/x9rd1NV/e+mvsn319tfoXh6KbBSYIi8iwwN7SwEyJyLnBRi1hnMBxF7HPvY9GqRRQUF7C1ZCsFJQXsLd/LZYMu4421bwAwe/lsADoldaJ/p/6c0OUEAkoPpZp03CQGdBoQEYWsJJ2GIzyi6dLBl3Lp4EvrvH7sjGyDoSHiiWidqpSK5PtVSn0gIn9MoE0GQ4fE7Xez5sAathZrYSgo0SJx1+l3Mb7PeHZV7eL3S39PujOdvMw8RvUYRV5WHpMHTObBMx5kwFMDWP+L9Ugd42n7d+pP/079E/odzPwKQ5h4xGO3iNxLdN3yq4DdiTPJYGi/uP1utpVsi3gOW0u2ckbeGfzo2B+x69Aurnz7SgDsFjvHZBxDn8w+JNmTADgh4wS++ulXZLmy6hSIuspbCjO/whAmHvGYCjyAHq4LsChUZjAklIYCxK1FUAXZW76XgmLtPXRP684ZeWdQ6avk5L+fjIpZSig3JZfBnQcDOvne7Atm0yezDz3SexwWW3BYHGQn1Z3M2jz1G9oS8QzVLQJuE5E0/VGVN3SMoX2zo3QHT337FFMGTok0hCd1OYkURwq7y3azpXgLoGcUh/eP7DESl83FtpJtbCnewt7CvWwp2IIKTUgY13scDquDTYWboscTPf5HfX+E1WJl9f7VbC3ZCsBTS56ib1ZfLBYL5x53LgDf7fuO3WW7kVCyZxHBYXVERv18t+87DlQeiO5HcNldnNZTDyndWLaRHdt2VDs+xZ7CsG7DAFi9fzVl3rLIfoB/r/83j5z1CADT3pnG9/u/x+2PLsR0fr/zOSPvDJLtydx5+p10S+1Gn8w+9MnsUy3dhsPqYHyf8U3+u7RFITUcvcSTGPFE4GUgO/T5IHCNUmp1gm0ztBDhhtBlc/HW2re457N7AHh3w7uROvOumMeAnAF8uuVTHlr80GHn+PR/PqVnek8+3Pwhf/r6T7owZjbQVz/9iuykbN7b+B5/X/b3w47//uffY8XK3HVz+ef3/4yU3/HRHQBsPmUzvxz1S177/jXmrp9b7dhMZybf3PANAM8ue5aPtnxUbX+PtB58ds1nALy47UWWr1pebX+/7H68f+X7ADy06CFW7F1xmH1h8RjceTAndDmBvMw8+mT2IS8rj87JnSP1rj/5+sOONRg6IvF0W/0duEMp9TmAiEwAZgOnN3SgiEwCngCswD+UUo/W2H8M8BJ6+K8VuDtmVNevgZ8CAeBWpdSCuL6RoUHCmU0Xb1/Mom2LWLJrCQ+e8SCTB0xmw8HDh2FOOX4KPdN1VrxzjjuHQV0GVXuyF5FIA3rR8RdxWq/T2LNxDz0G9IjsT3fqyQrTTprGef3Oq/bkL0ikC+emETdx5UlXIgjnvnou86/UKS2OzT4WgBmnzuDaodfq7xHyWmIX77lr9F38bMTPIt9ToXBYo6nYbup7E+l56ZHjFQqX1RXZ/8D4ByjzlgHw9tq3IwI64KkBgO46Mh6AwRCfeKSEhQNAKZUvIg2mvgzlw3oaOBvYCSwRkXlKqbUx1e4F3lBKzRKRQcB8oE/o/RXAYKA78ImI9FdK1bIWmSEelFKICGWeMi7610XsPLQTgL5ZfbnihCsY0Ek3jveMu4d7xt1T53j+Lild6JLSpc7r5KbmkpuaS9qeNPK6HD4VqKHjO6d0pnNK9Ek+LBphuqZ2pWtq1zqP75XRi17UvbDPMcnHkNet7ilK4dXlQHfF/eHsP5i5DQZDLcQjHltE5D7gldDnacCWOI4bCWxWSm0BEJE5wGQgVjwUEE52nUF0FNdkYI5SygMUiMjm0Pm+iuO6BrRYbCraxKJti1i8fTFdUrrw2NmPkeZMY8wxYzg+53jGHjM24lG0RUyA2GBou4iKzbBWWwWRLOC3wJhQ0WJgplKquIHjLgEmKaWuD32+Gp3e/ZaYOt2Aj4AsIAU4Sym1TESeAr5WSv0zVO854AOl1Fs1rnEjcCNAbm7u8Dlz5sT3rWsQVEHcfjdWy+FJgjyVHpzJziadN9HUZdtr219j/t75HPQeBKBPch/G5ozlqmOuivvcr2x7hat7X93strU2TbHrSO9FvLTVewbGtqbSUrb5g35S7PGthQJQXl5OamoqABMnTlymlGr0alvxjLYqBm5t7InjZCrwolLq/0TkNOAVETkh3oOVUrPR8RdGjBihJkyY0CQjyjxlrDu4jkxX5mH7ClYWkDe0bWZi2bJiC+4ebhZtW8S3u75l1gWzcFgdZPoyGW4fzthjxjK299h6u3nq4v6h9x+RbW31vjXFriO9F/HSVu8ZGNuaSkvZVuwuZmT3kXHPA8rPz6ep7WWY+hIjzqvvQKXUhQ2cexdU63zuGSqL5afApND5vhIRF5AT57FHLesPruellS/x+Q+fU/xf7QAOzBnI/or99EzvyS9O+UUrW2gwGDo69XkepwE70Nl0vwEaO7V1CdBPRPLQDf8VwJU16mxHp3p/UUQGAi7gADAPeE1E/oQOmPcDjso104MqyJr9a1i0fRFjeo1hSNchlHvL+bTgU4ZmDGXSkEmMOWZMvUFog8FgaG7qE4+u6JFSU9GN/n+A15VSa+I5sVLKLyK3AAvQw3CfV0qtEZHfAUuVUvOA/wWeFZHb0cHz6UoHYdaIyBvo4Lof+MXRMtLqr9/8lZtG3MQHmz9g8fbFfLH9C4qqihCEJFsSQ7oO4eRuJ/PlT79kx3c7yBvYNt11g8HQsakvq24A+BD4UEScaBHJF5HfKqWeiufkoTkb82uU3R/zfi0wuo5jHwYejuc6HYGiqiIKSgp4aslT3HzKzTy8+GEEYcwxYxjbeyxjjxkbSV1hEUu1uQ0Gg8HQ0tQbMA+Jxvlo4ehDdElaQzPxQ9EPvLjyRd5e93Yktfagvw0C4OYRN3Pbqbe1pnkGg8FQK/UFzF8GTkB7Dr816Uial9X7V/PkN0+ycNtCnFYnlwy6hGuGXMN5r51nJqQZDIY2T32exzSgArgNuDVmCJigEySm13WgoXa8AS/egJdURypFVUWs3r+aX478JVeeeGW92VQNBoOhrVFfzMN0qjcTxVXF/GvNv/jnd//kwgEXctfouxh7zFg+v+ZznLbqE4jMrGqDwdAeiCc9iaGJFBQX8NKql5i7fi5uv5sxvXTwG3RCwJrCASbttsFgaB8Y8UggTy15igWbF3DhgAuZPnR6wpcINRgMhpbCdE01E76Aj/c2vMdP3vhJJK35HafeQf70fH5/5u+NcBgMhg6F8TyOkFJ3KW+sfYNXVr3Cvop99M3qS4m7BIAe6T1a1ziDwWBIEEY8jgBfwMf5r53PgcoDnNbzNB6c+CBje481E/gMBkOHx4hHI1BKsXzvcj754RPuGn0Xdqudu0bfRb/sftUWETIYDIaOjhGPOPAH/Xz0w0e8uPJFVu1bRaYzk2knTaNHeg8uHNBQcmGDwWDoeBjxaICtFVu57pXr2F22mz4ZfXhg/ANcdPxFJNuTW9s0g8FgaDWMeNTCrkO72F22m1N6nEL3pO4M7jyYe8fdy8Q+E008w2AwGDDiEeHZZc/yo2N/xAsrX2DBDwvold6LBdMW4LA4eOq8uJIIGwwGw1GDEQ/gv9v/yz9W/IN/rPgHaY40rht2HdNOnBb3ko4Gg8FwtHHU98HMzJ/Jua+dG/lc5i3DZXXRLa1bK1plMBgMbZuj3vOYOWEmt596O5l/yDSp0A0GgyFOjnrPAzBBcIPBYGgkptUMcf2w61vbBIPBYGg3GPEIccPwG1rbBIPBYGg3GPEwGAwGQ6NJqHiIyCQR2SAim0Xk7lr2/1lEVoa2jSJSErMvELNvXiLtNBgMBkPjSNhoKxGxAk8DZwM7gSUiMk8ptTZcRyl1e0z9XwLDYk5RpZQamij7DAaDwdB0Eul5jAQ2K6W2KKW8wBxgcj31pwKvJ9Aeg8FgMDQTiRSPHsCOmM87Q2WHISK9gTzgs5hil4gsFZGvReSihFlpMBgMhkbTViYJXgG8pZQKxJT1VkrtEpG+wGci8r1S6ofYg0TkRuBGgNzcXPLz85t08aAK4va7KbYUH7bPU+mhYGVBk86baIxtjaet2gXGtqZibNPLRizctDDu+uXl5U1uL8MkUjx2Ab1iPvcMldXGFcAvYguUUrtCr1tEJB8dD/mhRp3ZwGyAESNGqAkTJjTJ0DJPGesOriPTlXnYvoKVBeQNzWvSeRONsa3xtFW7wNjWVIxtUOwuZmT3kXHn48vPz6ep7WWYRHZbLQH6iUieiDjQAnHYqCkROR7IAr6KKcsSEWfofQ4wGlhb81iDwWAwtA4J8zyUUn4RuQVYAFiB55VSa0Tkd8BSpVRYSK4A5iilVMzhA4G/i0gQLXCPxo7SMhgMhqMRf9BPIBjAF/ThD/pBgUJht9pb3JaExjyUUvOB+TXK7q/xeWYtx30JnJhI2wwGg6Gt4Q/6q20ASikEQYnCYXGQZEsizZlGki0Jp82JzWLDYXW0+BISbSVgbjAYDB0apVREFAIqgC/gA0AQEO1BuKwuXDYXGc4Mku3JOKwObBYbdqsdm8XWppK4GvEwGAyGZkApFelOCgQDEaEocZeAAgRcNhfJ9mRcNhdJtiTsVrveLFoc2tMCdEY8DAZDmyYQDOANePEGvARVECDSyCqlCAQDlFSVoFDVG18V+1ZVO0aQw8pjj6lZXtcxkS4lFBaxkGRLIsWeQrI9mSR7EhW2Ck7sciJ2qx2rWNuVODSEEQ+DwdBm8AV8eAPeSJcOAlaxkuZMo0tKF5LtyThtTuyWaIB48ebFnNz9ZEA35mFUjHrUVd6UY6qP7SHSpWSzHN6cWsRCkj2p/i/dTjHiYTB0QIKBIL5iH8qvqNFWNonO2Z1x73Ef+YliCDfIsY2xiGATG3bsiAiCICIECFAS+q8mGRkZbNqwqVltay4yMjJYt25da5sBgMvlomfPntjtzTMyy4iHwdAB8RX7yMnMITM7s1m6SjyVHpzJziYdq5RCoSKvoIPEFrFgFSsWiyXyuSm2lpWVkZaW1iTbEk1bsU0pRWFhITt37iQvr3kmLRrxMBg6IMqvmk04GnVdpQiqoI4LEL221WLFarFGBCLsURhaBhGhU6dOHDhwoNnOacTDYOiIKBLaONfmTYDu4w8PKQ0LRVsaXno009y/ByMehoQSfhINP42G3wdVsNo+BN3gxTytKhROm5Nke3LrfQFDJCYRCOq8pWGvwiIWbNaQUBDyKIw3cdRgxMNQKw01+gEVIKiCWOpIjxYIBiiu0lmKbRYbNqsNu8WOw+rAKtbI6JTwFn5StYgl0r3h8XvYV76P4qpiBCHVmVrriBbDkRMIwIIPLaxcIQwZEuDsSQEs1mh8AsBhdcTd7VRYWMiZZ54JwN69e7FarXTu3BmAb7/9FofDUeexS5cu5eWXX+bJJ5+s1+bTTz+dL7/8slHfsz5mzJjBm2++yY4dO7BYjLfUEOZfogHQYuEJeHD73LobQsBhcWC1WCPpD2IbfbvFXq0fu+b25eYvOaXHKUfUZeGyuchwZeDxeyiqKmJP2R68QW9kopXhyAg/IPgDisnnu1i6xEplBSSn2Bg5UvHhhwqbTXsYZZ6yRuVP6tSpEytXrgRg5syZpKamcuedd0b2+/1+bLbam58RI0YwYsSIBq/RnMIRDAaZO3cuvXr1YuHChUycOLHZzh1Lfd+7vdExvoWhSXgDXqp8VZGJV+nOdLpmdSXVkUqSLemIuyCaq6/baXPSLa0buam5lHnKjDfSSO68w8Z3q+SwEbsS+n9RobBuHQSDuqSiHBbmC8NPhk6ddN1AIAmrNXrs0KHwl780zo7p06fjcrlYsWIFo0eP5oorruC2227D7XaTlJTECy+8wIABA8jPz+fxxx/n/fffZ+bMmWzfvp0tW7awfft2ZsyYwa233gpAamoq5eXlLF68mD/+8Y/k5OSwevVqhg8fzj//+U9EhPnz53PHHXeQkpLC6NGj2bJlC++///5htuXn5zN48GAuv/xyXn/99Yh47Nu3j5tuuoktW7YAMGvWLE4//XRefvllHn/8cUSEk046iVdeeYXp06dzwQUXcMkll0Ts27NnD/n5+dx3331kZWWxfv16Nm7cyEUXXcSOHTtwu93cdttt3HjjjQB8+OGH/OY3vyEQCJCTk8PHH3/MgAED+PLLL+ncuTPBYJD+/fvz1VdfRTy51sL8qzuK8Af9uP3uyASsZHsy3dO6k+5MJ9mejNVibeAMrYtFLGS4Mow3Ug9KKbwBLwqdR0kQlLIA1mpdTbH/r6iAYLD6eYJBKC+PikdzsXPnTr788kusViuHDh1i8eLF2Gw2PvnkE37zm9/w9ttvH3bM+vXr+fzzzykrK2PAgAH8/Oc/P2yuwooVK1izZg3du3dn9OjR/Pe//2XEiBH87Gc/Y9GiReTl5TF16tQ67Xr99deZOnUqkydP5je/+Q0+nw+73c6tt97K+PHjmTt3LoFAgPLyctasWcNDDz3El19+SU5ODkVFRQ1+7+XLl7N69erIMNnnn3+e7OxsqqqqOOWUU/jJT35CMBjkhhtuiNhbVFSExWJh2rRpvPrqq8yYMYNPPvmEIUOGtLpwgBGPDk14hURPwANK91lnJ2WT5coi2Z7cKmmcmwvjjei/bzhtRyAYiAhDmiMNv/hx2VxYsPDUk/XHJ95/H6ZO1WIRJjUV/vpXuOAC/bmsrKpZ5itceumlWEMuTGlpKddccw2bNm1CRPD5fLUec/755+N0OnE6nXTp0oV9+/bRs2fPanVGjhwZKRs6dChbt24lNTWVvn37RhrsqVOnMnv27MPO7/V6mT9/Pn/6059IS0tj1KhRLFiwgAsuuIDPPvuMl19+GQCr1UpGRgYvv/wyl156KTk5OQBkZ2c3+L1HjhxZbX7Fk08+ydy5cwHYsWMHmzZt4sCBA4wbNy5SL3ze6667jsmTJzNjxgyef/55rr322gav1xJ0/H9hRxE14xYWsZCVlEUvVy9SHCm4bK7WNrHZOVq8kXB+J0/AE8mnJCKkO9PJScohxZGC0+bEaXUiIqw7uC5uAT33XBg1Cr75RnshKSn687nnNv/3SElJiby/7777mDhxInPnzmXr1q11rmzndEYnJ1qtVvx+f5Pq1MWCBQsoKSnhxBP1KhCVlZUkJSVxQVg548RmsxEMuXDBYBCv1xvZF/u98/Pz+eSTT/jqq69ITk5mwoQJuN11z97v1asXubm5fPbZZ3z77be8+uqrjbIrURjxaOd4A17cfndkGGW6M53czFxSHakk25OPqqGTtXkjRZVFWMTSrryR8EOAx++JxKNsFpuOSaV2JcmehNPqbLY1HKxWWLAAPvgAVq7U8Yxzz6VajCMRlJaW0qNHDwBefPHFZj//gAED2LJlC1u3bqVPnz7861//qrXe66+/zj/+8Y9It1ZFRQV5eXlUVlZy5plnMmvWLGbMmBHptjrjjDOYMmUKd9xxB506daKoqIjs7Gz69OnDsmXLuOyyy5g3b16dnlRpaSlZWVkkJyezfv16vv76awBOPfVUbr75ZgoKCiLdVmHv4/rrr2fatGlcffXVEc+ttWkf/5oMEWLjFuF1Abqldms3cYuWoD5vJNwYtxXCabw9fg/+oF93vYmQ7kinc3pn7VFYnThtTUsNEi9Wq+6iauTD9hFx1113cc011/DQQw9x/vnnN/v5k5KS+Nvf/sakSZNISUnhlFNOOaxOZWUlH374Ic8880ykLCUlhTFjxvDee+/xxBNPcOONN/Lcc89htVqZNWsWp512Gvfccw/jx4/HarUybNgwXnzxRW644QYmT57MkCFDItesjUmTJvHMM88wcOBABgwYwKmnngpA586dmT17NhdffDHBYJAuXbrw8ccfA3DhhRdy7bXXtpkuKwCpmSGyvTJixAi1dOnSJh1b5ilj3cF1ZLoyD9vXUgvY10XNuIXNYqNTcicyXZms+HoFEyckZkjhkZKfn19nN0RrEFRByjxlfP3F12QMyGg1byQco4jNGptqTyXDlcGGZRsYPXZ0pOvpSFi3bh0DBw5sBos1bSVHU23UZ1t5eTmpqakopfjFL35Bv379uP3229uEbY1h6dKl3H777SxevPiIzhP+XcT++xSRZUqphsdG18B4Hm2M8GiZKn8VSum4RaYrk17pvSJPodERM0dPl9SREvZGnDYnw7oNa5HYiD/ox+P34A1E+76T7El0SupEujMdl82F0+aMDGneLJs7ZFyqNXn22Wd56aWX8Hq9DBs2jJ/97GetbVKjefTRR5k1a1abiXWEMeLRRnD73VT5qhARUh2p9M7oredb2JNMbqBmJhGxkUAwEIlTRK5jdZLhzCDdmU6SPQmXzWW6FVuY22+/vUU9jURw9913c/fdd7e2GYdhxKMV8Qf9VHgrCKgA6Y50jss+jgxXRrsJ7LZ3mjpSK6iCEY8inBTQKlbSnen0SOsREQrzdzR0ZMyvu4UJqiCVvkq8fi9Om5Oe6T3JSsoy3RWtTH3eiMvuisylAJ1ePM2RRm5qbmQ9aoe17lxNBkNHJKHiISKTgCcAK/APpdSjNfb/GQhHfJOBLkqpzNC+a4B7Q/seUkq9lEhbE024Wwqgc3JnOmd3JtWRelQNpW0P1OaNlLpL6ZTUiVRHakQozN/NcLSTMPEQESvwNHA2sBNYIiLzlFJrw3WUUrfH1P8lMCz0Pht4ABiBXkRzWejY4kTZmwh8AR8V3gqCBEl3pNMvux/prnTTndFOCHsj3dK6tbYpBkObI5GR2JHAZqXUFqWUF5gDTK6n/lTg9dD7c4CPlVJFIcH4GJiUQFubjaAKUu4tp7iqGG/AS6+MXgztOpRBXQaRnZxthMNwVDBx4kQWLFhQrewvf/kLP//5z+s8ZsKECYSH25933nmUlJQcVmfmzJk8/vjj9V773XffZe3ayDMq999/P5988kkjrK+fGTNm0KNHj8hs8qOVRLZkPYAdMZ93AqNqqygivYE84LN6ju1Ry3E3AjcC5Obmkp+f3yRDw3Mpii2HOzaeSg8FKwviOkd4AprdYsdmsVElVZRS2iSb4qG8vLzJ3znRtFXb2qpd0Ly2ZWRkUFZW1ujjfv/l7/nN6b85rDwQCDTqfFOmTOGVV17h9NNPj5S9+uqrPPjgg3WeJxAIUFFRQVlZWWQ2eM26Ho8Hu91erbymbW+++SaTJk2iV69eAPy///f/aj1XUwgGg7zzzjt0796dDz74gHHjxtVbv7H3LUyiUre73W7y8/Ob5bfWVh6DrwDeUkoFGnOQUmo2MBv0JMGmTkpr6iTBmt1SXVO7tmi3VFubiBdLW7WtrdoFzWvbunXrqk1Om/Di4ee9bPBl3HzKzVT6Kjnv1fMAWLhtIV/t+QqA6UOnM33odA5WHmTKG1OqpcXIn55f7/WnTZvGQw89hNPpxOFwsHXrVvbt28c555zDzTffzJIlS6iqquKSSy7ht7/9LaBzUqWkpJCWlkafPn1YunQpOTk5PPzww7z00kt06dKFXr16MXz4cNLS0nj22WeZPXs2breb/v3788orr7By5Uo++OADvvzyS/7v//6Pt99+mwcffDCSKv3TTz/lzjvvxO/3c8oppzBr1iycTid9+vThmmuu4b333sPn8/Hmm29y/PHHH/a9PvvsM0444QQuv/xy/v3vf0dmxteVuv3vf/87Tz/9dIOp28ONeaJTt7tcLoYNG9Ysv7VEdlvtAnrFfO4ZKquNK4h2WTX22BbFdEsZOiJbS7aycNtCQAvIwm0LeXf9u00+X3Z2NiNHjuSDDz4AYM6cOVx22WWICA8//DBLly7lu+++Y+HChXz33Xd1nmfZsmXMmTOHlStXMn/+fJYsWRLZd/HFF7NkyRK+/PJLBg4cyHPPPcfpp5/OhRdeyGOPPcbKlSs59thjI/XdbjfTp0/nX//6F99//z1+v59Zs2ZF9ufk5LB8+XJ+/vOf19k1Fk7dPmXKFP7zn/9E8leFU7evWrWK5cuXM3jwYNasWcNjjz3GZ599xqpVq3jiiScavG/Lly/niSeeYOPGjYBO3b5s2TKWLl3Kk08+SWFhIQcOHOCGG27g7bffZtWqVbz55pvVUrcDLZK6PZEt3RKgn4jkoRv+K4Ara1YSkeOBLOCrmOIFwO9FJCv0+UfArxNoa4O4/W4qvZWICJ2TO9MltQsp9hQz6sbQLqjPU0i2J7N1xlYA5LeCeqB6yqKc5BzmXza/0Wk2pk6dypw5c5g8eTJz5szhueeeA+CNN95g9uzZ+P1+9uzZw9q1aznppJNqPcfixYuZMmUKycl6zs2FF14Y2bd69WruvfdeioqKqKys5JxzzqnXng0bNpCXl0f//v0BuOaaa3j66aeZMWMGoMUIYPjw4bzzzjuHHd+U1O1TpkzpsKnbEyYeSim/iNyCFgIr8LxSao2I/A5YqpSaF6p6BTBHxSTZUkoViciDaAEC+J1SquEVV5oZX8AXWYs7zZFG/079zWgpgyFOJk+ezO23387y5cuprKxk+PDhFBQU8Pjjj7NkyRKysrKYPn16venI62P69Om8++679O3bl7fffvuI+/DDad3rSuluUrdXJ6F5L5RS85VS/ZVSxyqlHg6V3R8jHCilZiqlDpt7r5R6Xil1XGh7IZF2xlKzW8putTOk6xDTLWU4Knhg/APNdq7U1FQmTpzIddddF0l3fujQIVJSUsjIyGDfvn2Rbq26GDduHO+++y5VVVWUlZXx3nvvRfaVlZXRrVs3fD5ftYYyLS2t1iD1gAED2Lp1K5s3bwbglVdeYfz48XF/n3Dq9q1bt7J161YKCgr4+OOPq6VuBx0kLy0t5YwzzmDu3LkUFhYCRFYcDKduB5qcun3RokUUFBRUOy9EU7fHLrqVKEzSpBC+gI+iSj0hLNOZyeAugxnadSh2i93M/jYcNcycMLNZzzd16lRWrVoVEY8hQ4YwbNgwjj/+eK688kpGjx5d7/Enn3wyl19+OUOGDOHcc8+tllb9wQcfZNSoUZx99tnVgttXXHEFjz32GMOGDeOHH36IlLtcLl544QUuvfRSTjzxRCwWCzfddFNc3yOcuj02dXzN1O2ff/45J554IsOHD2ft2rUMHjyYO++8k/HjxzNkyBDuuOMOAG644QYWLlzIkCFD+Oqrr+pN3e73+xk4cCB33313ranbhwwZwuWXXx455sILL6S8vLxlUrcrpTrENnz4cNVUKr2VasPBDaqwolD5Ar5q+z7//PMmnzfRGNsaT1u1S6nmtW3t2rXNdi6llDp06FCznq85MbZFWbJkiRozZkyd+8O/i9jfGjqM0Og21/TBoNNk9+/Uv7XNMBgMhibT0qnbTbeVwWAwdADuvvtutm3bxpgxY1rkekY8DIYOiuogq4Qamofm/j0Y8TAYOiAul4vCwkIjIAZAC0dhYSEuV/MN/jExD4OhA9KzZ0927tzJgQMHmuV8bre7WRue5sTYFh8ul4uePXs22/mMeBgMHRC73V5tpvKRkp+fz7Bhw5rtfM2Jsa11MN1WBoPBYGg0RjwMBoPB0GiMeBgMBoOh0UhHGY0hIgeAbQk4dQ5wMAHnbQ6MbY2nrdoFxramYmxrPLF29VZKNTp3e4cRj0QhIkuVUiNa247aMLY1nrZqFxjbmoqxrfE0h12m28pgMBgMjcaIh8FgMBgajRGPhpnd2gbUg7Gt8bRVu8DY1lSMbY3niO0yMQ+DwWAwNBrjeRgMBoOh0RjxMBgMBkOjMeIRQkR6icjnIrJWRNaIyG2h8pkisktEVoa281rJvq0i8n3IhqWhsmwR+VhENoVes1rBrgEx92aliBwSkRmtdd9E5HkR2S8iq2PKar1PonlSRDaLyHcicnIr2PaYiKwPXX+uiGSGyvuISFXM/XumFWyr828oIr8O3bcNInJOC9v1rxibtorIylB5S9+zutqMVv+91WNb8/3emrL8YEfcgG7AyaH3acBGYBAwE7izDdi3FcipUfZH4O7Q+7uBP7SyjVZgL9C7te4bMA44GVjd0H0CzgM+AAQ4FfimFWz7EWALvf9DjG19Yuu10n2r9W8Y+nexCnACecAPgLWl7Kqx//+A+1vpntXVZrT6760e25rt92Y8jxBKqT1KqeWh92XAOqBH61rVIJOBl0LvXwIuaj1TADgT+EEplYiZ/nGhlFoEFNUorus+TQZeVpqvgUwR6daStimlPlJK+UMfvwaaL2d2I6jjvtXFZGCOUsqjlCoANgMjW9ouERHgMuD1RFy7IeppM1r991aXbc35ezPiUQsi0gcYBnwTKrol5OY93xpdQyEU8JGILBORG0NluUqpPaH3e4Hc1jEtwhVU/4fcFu4b1H2fegA7YurtpHUfGK5DP5mGyRORFSKyUETGtpJNtf0N28p9GwvsU0ptiilrlXtWo81oU7+3WtqzMEf0ezPiUQMRSQXeBmYopQ4Bs4BjgaHAHrSb3BqMUUqdDJwL/EJExsXuVNr3bLVx1yLiAC4E3gwVtZX7Vo3Wvk91ISL3AH7g1VDRHuAYpdQw4A7gNRFJb2Gz2uTfMIapVH9YaZV7VkubEaG1f2912dYcvzcjHjGIiB19o19VSr0DoJTap5QKKKWCwLMkyD1vCKXUrtDrfmBuyI59Ybc39Lq/NWwLcS6wXCm1D9rOfQtR133aBfSKqdczVNaiiMh04ALgqlBjQ6hLqDD0fhk6rtC/Je2q52/Y6vdNRGzAxcC/wmWtcc9qazNoI7+3Omxrtt+bEY8Qof7T54B1Sqk/xZTH9klOAVbXPLYFbEsRkbTwe3TQazUwD7gmVO0a4N8tbVsM1Z4C28J9i6Gu+zQP+J/QKJhTgdKY7oYWQUQmAXcBFyqlKmPKO4uINfS+L9AP2NLCttX1N5wHXCEiThHJC9n2bUvaBpwFrFdK7QwXtPQ9q6vNoA383uppz5rv95aoaH9724AxaPfyO2BlaDsPeAX4PlQ+D+jWCrb1RY9uWQWsAe4JlXcCPgU2AZ8A2a1071KAQiAjpqxV7htawPYAPnSf8k/ruk/oUS9Po5+yvgdGtIJtm9H94OHf3DOhuj8J/a1XAsuBH7eCbXX+DYF7QvdtA3BuS9oVKn8RuKlG3Za+Z3W1Ga3+e6vHtmb7vZn0JAaDwWBoNKbbymAwGAyNxoiHwWAwGBqNEQ+DwWAwNBojHgaDwWBoNEY8DAaDwdBojHgY2h0i0ikm++deqZ751dHAsSNE5Mk4rvFlM9k6QURKQ2kfNojIIhG5IM7jTm/ktZJF5FXR2ZdXi8gXoRnGzfZ9DIYwttY2wGBoLErPhB0KOm04UK6Uejy8X0RsKpr8reaxS4GlcVyjUQ13AyxWSl0Qsm0o8K6IVCmlPq3nmAlAOdCYRv82dK6nE0PXGoCeH9Hc38dgMJ6HoWMgIi+KyDMi8g3wRxEZKSJfhZ74vww1pOEn+vdD72eGEv7li8gWEbk15nzlMfXzReQt0esgvBqavYuInBcqWyZ6nYb3G7JTKbUS+B1wS+gcPxaRb0J2fiIiuaFEdjcBt4e8qbG11avl9N2ISXehlNqglPLU+D6/i/HSdonIC6HyaSLybaj87+HZxgZDXRjxMHQkegKnK6XuANYDY5VO9HY/8Ps6jjkeOAedt+mBUD6gmgwDZqDXQ+gLjBYRF/B39Ozq4UDnRti5PHRdgC+AU0N2zgHuUkptBZ4B/qyUGqqUWlxbvVrO+zzwq5BoPiQi/WpWUErdr5QaivZsioCnRGQgcDkwOrQvAFzViO9jOAox3VaGjsSbSqlA6H0G8FKoAVVAbaIA8J/Q07lHRPaj02fvrFHnWxXKoSR61bo+6C6lLUqvZwE6jcaNxIfEvO8J/CuUR8oBFNR+SMP1lFIrQ3mJfoTO/bRERE5TSq2rdnHtOf0T+JNSapmI3AIMD9UHSKJ1k2wa2gHG8zB0JCpi3j8IfK6UOgH4MeCq4xhPzPsAtT9QxVOnMQxDL84D8FfgqVCc4mf12BlXPaVUuVLqHaXUzWiBqG3535nATqXUC6HPArwU8nKGKqUGKKVmNuF7GY4ijHgYOioZRPv/pyfg/BuAvqH4BOhunwYRkZOA+9AJ8qC6ndfEVC1DLx9KA/Vizz1aoutlO9DdbNtq1Pkx2iu5Nab4U+ASEekSqpMtIr3j+T6GoxcjHoaOyh+BR0RkBQnonlVKVQE3Ax+KyDJ0Y19aR/Wx4aG6aNG4NWak1UzgzdA5DsYc8x4wJRwwr6deLMcCC0Xke2AFelTZ2zXq3IFevS4cHP+dUmotcC96pcrvgI/RwXeDoU5MVl2DoYmISKpSqjwUQ3ga2KSU+nNr22UwtATG8zAYms4NoQD6GnS30t9b1xyDoeUwnofBYDAYGo3xPAwGg8HQaIx4GAwGg6HRGPEwGAwGQ6Mx4mEwGAyGRmPEw2AwGAyN5v8DiknMF12zyoMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Use learning curve to get training and validation scores along with train sizes\n",
    "train_sizes, train_scores, val_scores = learning_curve(estimator=logreg_model, X=X_train, y=y_train, cv=10, train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=1)\n",
    "\n",
    "# Calculate training and test mean and std\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, val_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, val_mean + val_std, val_mean - val_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that this result means that a training and validation set size of 130 is optimal.  It is where the learning curves for the two data sets are closest (converged).\n",
    "\n",
    "My dataset is 303 samples.  If I split the training and validation sets into 130 samples, I'd have 43 samples left over for testing.  That's a very small number. \n",
    "\n",
    "One of the strategies I could use to generate more data is bagging and/or boosting the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hyperparameter tuning](https://realpython.com/train-test-split-python-data/), also called hyperparameter optimization, is the process of determining the best set of hyperparameters to define your machine learning model. sklearn.model_selection provides you with several options for this purpose, including GridSearchCV, RandomizedSearchCV, validation_curve(), and others. Splitting your data is also important for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Ensemble Learning \n",
    "\n",
    "At this stage, purely out of curiousity, I'd like to implement a Random Forest algorithm (classifier) and see how it compares to the Logsistic Regression model.\n",
    "\n",
    "I can actually boost the accuracy of my predictions, by implementing both - in an [ensemble learning approach](https://youtu.be/m-S9Hojj1as).\n",
    "\n",
    "![Ensemble Learning](images\\Ensemble_Learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit my data to a Random Forest model\n",
    "\n",
    "A [decision tree](https://in.springboard.com/blog/decision-tree-implementation-in-python/) is a simple representation for classifying examples. \n",
    "\n",
    "It is a supervised machine learning technique where the data is continuously split according to a certain parameter. \n",
    "\n",
    "Decision tree analysis can help solve both classification & regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevant library\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Decision Tree classifier object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Decision Tree Classifier on the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree_model = dectree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions using the Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree_predictions = dectree.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7049180327868853\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy score\n",
    "print(accuracy_score(dectree_predictions, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  9]\n",
      " [ 9 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(dectree_predictions, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        28\n",
      "           1       0.73      0.73      0.73        33\n",
      "\n",
      "    accuracy                           0.70        61\n",
      "   macro avg       0.70      0.70      0.70        61\n",
      "weighted avg       0.70      0.70      0.70        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,dectree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The decision tree performs less well than logistic regression!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0492\n",
       "                \n",
       "                    &plusmn; 0.0776\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0459\n",
       "                \n",
       "                    &plusmn; 0.0636\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0459\n",
       "                \n",
       "                    &plusmn; 0.0981\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0491\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0131\n",
       "                \n",
       "                    &plusmn; 0.0482\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0033\n",
       "                \n",
       "                    &plusmn; 0.0382\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0098\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 92.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0131\n",
       "                \n",
       "                    &plusmn; 0.0636\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(dectree_model, random_state=1).fit(X_val, y_val)\n",
    "dectree_feat_importance = eli5.show_weights(perm, feature_names = X_val.columns.tolist())\n",
    "dectree_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to Logistic Regression Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0754\n",
       "                \n",
       "                    &plusmn; 0.0491\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0525\n",
       "                \n",
       "                    &plusmn; 0.0382\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0492\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0814\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0359\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0066\n",
       "                \n",
       "                    &plusmn; 0.0491\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the two different models placed differing weights of importance on the features.\n",
    "\n",
    "Thalach (maxiumum heart rate) and cholestrol weighted very differently in the two models.\n",
    "\n",
    "This is a very interesting finding, because if I had only used Logistic Regression, I would have proceeded to drop the least important features to improve accuracy.\n",
    "\n",
    "This demonstrates - especially because I have a small data set (303 samples) - that ensemble learning will give better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Use Bagging Technique to Combine Logistic Regression and Decision Tree Models](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/#:~:text=%20Advanced%20Ensemble%20techniques%20%201%203.1%20Stacking.,of%20multiple%20models%20%28for%20instance%2C%20all...%20More%20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
