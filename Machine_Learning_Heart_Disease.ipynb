{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview ##\n",
    "\n",
    "This notebook contains my first full walk-through of the machine learning model creation process.\n",
    "\n",
    "The notebook includes numerous links to internet resources about each of the steps.\n",
    "\n",
    "At some points in the process, I focused more on exploring areas of interest (feature importance, comparing/contrasting two different models) rather than on crafting a highly accurate model (through hyperparameter tuning and iterative accuracy checks).\n",
    "\n",
    "Therefore, the code in this notebook represents more of a sampling of machine learning techniques - and documentation about how they guide next steps - rather than a finished/deployable product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are some things I am curious about, after exploring the data:**\n",
    "1. Do any of the features strongly predict heart disease on their own?\n",
    "2. Which combinations of features boost heart disease prediction the most?\n",
    "3. Are any of the features less related...unless combined with others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But first, I need to select an appropriate machine learning algorithm.**\n",
    "\n",
    "[These are the important considerations:](https://www.kdnuggets.com/2020/05/guide-choose-right-machine-learning-algorithm.html#:~:text=%20An%20easy%20guide%20to%20choose%20the%20right,time.%20Higher%20accuracy%20typically%20means%20higher...%20More%20)\n",
    "\n",
    "1. *Size of the training data (small in this case)*\n",
    "\n",
    "    if the training data is smal or if the dataset has a small number of observations/high number of features \n",
    "    choose algorithms with high bias/low variance like Linear regression, Naïve Bayes, or Linear SVM.\n",
    "    \n",
    "    If the training data is large and the number of observations is higher, compared to the number of \n",
    "    features, you can use low bias/high variance algorithms like KNN, Decision trees, or kernel SVM.\n",
    "    \n",
    "\n",
    "2. *Desired Accuracy and/or Interpretability of the output (interpretability in this case)*\n",
    "\n",
    "    Accuracy of a model means that the function predicts a response value for a given observation, which is \n",
    "    close to the true response value for that observation. \n",
    "    \n",
    "    A highly interpretable algorithm (restrictive models like Linear Regression) means that one can easily \n",
    "    understand how any individual predictor is associated with the response while the flexible models give \n",
    "    higher accuracy at the cost of low interpretability.\n",
    "    \n",
    "    \n",
    "3.  *Speed or Training time (non-issue for this small dataset)*\n",
    "\n",
    "    Higher accuracy typically means higher training time. Also, algorithms require more time to train on \n",
    "    large training data. In real-world applications, the choice of algorithm is driven by these two factors \n",
    "    predominantly.\n",
    "\n",
    "    Algorithms like Naïve Bayes and Linear and Logistic regression are easy to implement and quick to run. \n",
    "    Algorithms like SVM, which involve tuning of parameters, Neural networks with high convergence time, and \n",
    "    random forests, need a lot of time to train the data.\n",
    "    \n",
    "    \n",
    "4. *Linearity (to be determined)*\n",
    "\n",
    "    The best way to find out the linearity is to either fit a linear line or run a logistic regression or SVM \n",
    "    and check for residual errors. A higher error means the data is not linear and would need complex \n",
    "    algorithms to fit.\n",
    "    \n",
    "\n",
    "5. *Number of features (small in this case)*\n",
    "\n",
    "    The dataset may have a large number of features that may not all be relevant and significant. For a \n",
    "    certain type of data, such as genetics or textual, the number of features can be very large compared to \n",
    "    the number of data points.\n",
    "    \n",
    "\n",
    "6. *Supervised or Unsupervised learning (Supervised in this case)*\n",
    "\n",
    "   Supervised learning algorithms are used when the training data has output variables corresponding to the \n",
    "   input variables. The algorithm analyses the input data and learns a function to map the relationship \n",
    "   between the input and output variables.\n",
    "   \n",
    "   Unspervised learning algorithms are used when the training data does not have a response variable. Such \n",
    "   algorithms try to find the intrinsic pattern and hidden structures in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I am going to start with a Linear or Logistic regression algorithm and evaluate whether the data is non-linear.**  \n",
    "\n",
    "If non-linear, I will apply random forests (because they are easy to interpret).\n",
    "\n",
    "[The choice between Linear or Logistic regression, depends on what type of output I am expecting:](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "I am expecting to output a category (Logistic Regression): yes - heart disease or no - not heart disease.\n",
    "\n",
    "I am not expecting to output a quantity (Linear Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit my data to a logistic regression model\n",
    "\n",
    "[Instead of predicting exactly 0 or 1, logistic regression generates a probability—a value between 0 and 1, exclusive.](https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "heart_data = pd.read_csv(\"data/heart.csv\")\n",
    "\n",
    "#preview the columns\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data for the model by:**\n",
    "1. determining the target\n",
    "2. separating the features from the label \n",
    "3. splitting out the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determine the target (y) and separate label (y) from features (X)\n",
    "target = 'target'\n",
    "y = heart_data[target]\n",
    "X = heart_data.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data for model training, tuning, and evaluation**\n",
    "\n",
    "60% - train set\n",
    "\n",
    "20% - validation set\n",
    "\n",
    "20% - test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is applied to train, or fit, your model.\n",
    "\n",
    "The validation set is used for unbiased model evaluation during hyperparameter tuning.\n",
    "\n",
    "The test set is needed for an unbiased evaluation of the final model.\n",
    "\n",
    "In less complex cases, when you don’t have to tune hyperparameters, it’s okay to work with only the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the heart dataset into a Training Set and a Testing Set (testing set = = test_size = 20% of data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7, stratify=y)\n",
    "\n",
    "### Then split the Training Set, to set aside a Validation Set (validation set = test_size = 20% of data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=7, stratify=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_size:** is the number that defines the size of the training set. \n",
    "\n",
    "**test_size** is the number that defines the size of the test set.\n",
    "\n",
    "You should provide either train_size or test_size. \n",
    "\n",
    "If you provide a float, then it must be between 0.0 and 1.0 and will define the share of the dataset used.  If you provide an int, then it will represent the total number of the samples. \n",
    "\n",
    "The default value is None and then the default share of the dataset that will be used for testing is 0.25, or 25 percent.\n",
    "\n",
    "**random_state** is the object that controls randomization during splitting. \n",
    "\n",
    "Set any non-negative value, to make your tests reproducible. The default value is None.\n",
    "\n",
    "**Stratified splits** are desirable when you’re classifying an imbalanced dataset, a dataset with a significant difference in the number of samples that belong to distinct classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Train the model](https://realpython.com/train-test-split-python-data/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable called ml_model and use it to instantiate (call) the logistic regression classifer\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#fit the classifier to the training data - the training features and the training labels are passed in\n",
    "logreg_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Predictions Using the Validation Set**\n",
    "\n",
    "Reserve the Testing Set for evaluating predictions on the finalized Logistic Regression Model.\n",
    "\n",
    "Generate the first round(s) of evaluating model performance, using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predict command on the classifier and providing it with the parameters it needs to make predictions about\n",
    "#which are the features in your testing dataset\n",
    "log_predictions = logreg_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Evaluate the Predictions**](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Logistic Regression outputs predictions about test data points on a binary scale, zero or one.](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)\n",
    "\n",
    "If the value of something is 0.5 or above, it is classified as belonging to class 1, while below 0.5 if is classified as belonging to 0.\n",
    "\n",
    "Each of the features also has a label of only 0 or 1. \n",
    "\n",
    "Logistic regression is a linear classifier and therefore used when there is some sort of linear relationship between the data.\n",
    "\n",
    "The Target feature refers to whether the patient has heart disease or not.\n",
    "\n",
    "Values are:\n",
    "\n",
    "0 = absent\n",
    "\n",
    "1 = present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Score**\n",
    "\n",
    "Accuracy score is the simplest way to evaluate how the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "#pass in the predictions against the ground truth labels which were stored in the validation set labels\n",
    "print(accuracy_score(log_predictions, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, while it can give you a quick idea of how your classifier is performing, it is best used when the number of observations/examples in each class is roughly equivalent.\n",
    "\n",
    "Because this doesn't happen very often, other metrics are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix and Classification Report**\n",
    "\n",
    "The Confusion Matrix and [Classification Report](https://datascience.stackexchange.com/questions/64441/how-to-interpret-classification-report-of-scikit-learn) give more details about performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  3]\n",
      " [10 30]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(log_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of correct predictions for each class run on the diagonal from top-left to bottom-right.\n",
    "\n",
    "This Logistic Regression model is better at predicting 'heart disease present' (1-value) than 'heart disease absent' (0-value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73        28\n",
      "           1       0.75      0.91      0.82        33\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.80      0.78      0.78        61\n",
      "weighted avg       0.80      0.79      0.78        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,log_predictions))\n",
    "\n",
    "#precision - this model predicted 0 with 86% accuracy and 1 with 75% accuracy.  \n",
    "#recall - this model was right 64% of the time when it predicted 0 and was right 91% of the time when it predicted 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recall means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "The precision will be \"how many are correctly classified among that class\"\n",
    "\n",
    "f1-score is an average of precision and recall.\n",
    "\n",
    "The support is the number of occurence of the given class in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area Under ROC Curve (AUC)**\n",
    "\n",
    "This metric is only used binary classification problems. \n",
    "\n",
    "The area under the curve represents the model's ability to properly discriminate between negative and positive examples, between one class or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775974025974026\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 1.0 = all of the area falls under the curve and this represents a perfect classifier. \n",
    "\n",
    "In contrast, an AUC of 0.5 is basically as good as randomly guessing.\n",
    "\n",
    "This model is a moderately good at predicting heart disease, using this AOC measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After fitting a basic Logistic model, the conclusion is that it is a fairly good predictor of heart disease (75%+ accuracy/precision).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Determine Feature Importance](https://www.kaggle.com/dansbecker/permutation-importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features have the biggest impact on predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the eli5 library\n",
    "\n",
    "import eli5 \n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[eli5](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html) provides a way to compute feature importances for any black-box estimator by measuring how score decreases when a feature is not available.\n",
    "\n",
    "The method is also known as “permutation importance” or “Mean Decrease Accuracy (MDA)”.\n",
    "\n",
    "The idea is the following: feature importance can be measured by looking at how much any score we’re interested decreases when a feature is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this is another reference](https://medium.com/@lily_su/explaining-predictions-graphing-feature-importances-permutation-importances-with-eli5-partial-839b58eee962)\n",
    "\n",
    "[and a third reference](https://medium.com/analytics-vidhya/why-should-i-trust-your-model-bdda6be94c6f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0623\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0426\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0393\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0814\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0393\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0033\n",
       "                \n",
       "                    &plusmn; 0.0865\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(logreg_model, random_state=1).fit(X_val, y_val)\n",
    "log_feat_importance = eli5.show_weights(perm, feature_names = X_val.columns.tolist())\n",
    "log_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is showing the most important features (in green, from top to bottom).\n",
    "\n",
    "The first number in each row shows how much model performance decreased with a random shuffling (in this case, using \"accuracy\" as the performance metric).\n",
    "\n",
    "You'll occasionally see negative values for permutation importances.  This happens when the feature didn't matter (should have had an importance close to 0), but random chance caused the predictions on shuffled data to be more accurate. This is more common with small datasets, like the one in this example, because there is more room for luck/chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Examine the Learning Curve](https://vitalflux.com/learning-curves-explained-python-sklearn-example/)**\n",
    "\n",
    "[A learning curve](https://realpython.com/train-test-split-python-data/), sometimes called a training curve, shows how the prediction score of training and validation sets depends on the number of training samples. It plots the optimal value of a model's loss function for a training set against this loss function evaluated on a validation data set. \n",
    "\n",
    "You can use learning_curve() to get this dependency, which can help you find out how much a machine learning model benefits from adding more training data and whether the estimator suffers more from a variance or bias error.  If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Use learning curve to get training and validation scores along with train sizes\n",
    "train_sizes, train_scores, val_scores = learning_curve(estimator=logreg_model, X=X_train, y=y_train, cv=10, train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=1)\n",
    "\n",
    "# Calculate training and test mean and std\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, val_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "plt.fill_between(train_sizes, val_mean + val_std, val_mean - val_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Model accuracy')\n",
    "plt.grid()\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that this result means that a training and validation set size of 130 is optimal.  It is where the learning curves for the two data sets are closest (converged).\n",
    "\n",
    "My dataset is 303 samples.  If I split the training and validation sets into 130 samples, I'd have 43 samples left over for testing.  That's a very small number. \n",
    "\n",
    "I could employ strategies to generate more data, but instead I'm going to pursue additional techniques for boosting model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Ensemble Learning \n",
    "\n",
    "At this stage, purely out of curiousity, I'd like to implement a Decision Tree algorithm (classifier) and see how it compares to the Logsistic Regression model.\n",
    "\n",
    "I can actually boost the accuracy of my predictions, by implementing both - in an [ensemble learning approach](https://youtu.be/m-S9Hojj1as).\n",
    "\n",
    "![Ensemble Learning](images\\Ensemble_Learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit my data to a Decision Tree model\n",
    "\n",
    "A [decision tree](https://in.springboard.com/blog/decision-tree-implementation-in-python/) is a simple representation for classifying examples. \n",
    "\n",
    "It is a supervised machine learning technique where the data is continuously split according to a certain parameter. \n",
    "\n",
    "Decision tree analysis can help solve both classification & regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the relevant library\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Decision Tree classifier object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Decision Tree Classifier on the Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree_model = dectree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Predictions using the Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree_predictions = dectree.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Decision Tree Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7540983606557377\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy score\n",
    "print(accuracy_score(dectree_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model accuracy was: 0.7868852459016393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  7]\n",
      " [ 8 26]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(dectree_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression confusion matrix was:\n",
    "\n",
    " [[18  3]\n",
    "    \n",
    " [10 30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73        28\n",
      "           1       0.76      0.79      0.78        33\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.75      0.75      0.75        61\n",
      "weighted avg       0.75      0.75      0.75        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,dectree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression classification report yielded these results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73        28\n",
      "           1       0.75      0.91      0.82        33\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.80      0.78      0.78        61\n",
      "weighted avg       0.80      0.79      0.78        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751082251082251\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_val,dectree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression score was actually higher at: 0.775974025974026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The decision tree performs similarly to the logistic regression model.**  \n",
    "\n",
    "It yields better results on some measures, and worse on others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Decision Tree Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0622\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0492\n",
       "                \n",
       "                    &plusmn; 0.0415\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0393\n",
       "                \n",
       "                    &plusmn; 0.0533\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0564\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0328\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0295\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0131\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0066\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0098\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0262\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(dectree_model, random_state=1).fit(X_val, y_val)\n",
    "dectree_feat_importance = eli5.show_weights(perm, feature_names = X_val.columns.tolist())\n",
    "dectree_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Logistic Regression Feature Importance, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0623\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0426\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0393\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0814\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0393\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0033\n",
       "                \n",
       "                    &plusmn; 0.0865\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the two different models placed differing weights of importance on the features.\n",
    "\n",
    "Thalach (maxiumum heart rate) and cholestrol weighted very differently in the two models.\n",
    "\n",
    "This is a very interesting finding, because if I had only used Logistic Regression, I would have proceeded to drop the least important features to improve accuracy.\n",
    "\n",
    "This demonstrates - especially because I have a small data set (303 samples) - that ensemble learning will give better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Use Bagging Technique to Combine Logistic Regression and Decision Tree Models](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/#:~:text=%20Advanced%20Ensemble%20techniques%20%201%203.1%20Stacking.,of%20multiple%20models%20%28for%20instance%2C%20all...%20More%20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind bagging is combining the results of multiple models (for instance, all decision trees) to get a generalized result. \n",
    "\n",
    "Bootstrapping is a sampling technique in which we create subsets of observations from the original dataset, with replacement. \n",
    "\n",
    "Bagging (or Bootstrap Aggregating) technique uses these subsets (bags) to get a fair idea of the distribution (complete set). \n",
    "\n",
    "The size of subsets created for bagging may be less than the original set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Re-Create the Logistic Regression and Decision Tree models, using a Bagging Classifier](https://vitalflux.com/bagging-classifier-python-code-example/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import relevant libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an empty list to hold the results of the various models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a Pipeline Estimator for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipeline = make_pipeline(StandardScaler(), LogisticRegression(random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate (call in) the bagging classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_bagging_classifier = BaggingClassifier(base_estimator=log_pipeline, n_estimators=100, max_features=13, random_state=1, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the results of the bagging classifier to the list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(('logistic', Log_bagging_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, create a Pipeline Estimator for the Decision Tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipeline = make_pipeline(StandardScaler(), DecisionTreeClassifier(random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate (call in) the bagging classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bagging_classifier = BaggingClassifier(base_estimator=tree_pipeline, n_estimators=100, max_features=13, random_state=1, n_jobs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the results of the bagging classifier to the list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators.append(('tree', tree_bagging_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Combine the two 'bagged' models into an Ensemble model, using the Voting Classifier](https://www.datacamp.com/community/tutorials/ensemble-learning-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import relevant libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the ensemble model using the voting classifier method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the ensemble classifier (model) to the heart dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = ensemble.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the Ensemble Model to generate predictions on the validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = ensemble.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Ensemble Model Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "#print the accuracy score\n",
    "print(accuracy_score(ensemble_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree accuracy was: 0.7540983606557377\n",
    "\n",
    "The Logistic Regression accuracy was: 0.7868852459016393\n",
    "\n",
    "The ensemble model's accuracy matches the Logistic Regression model (which was the higher of the two)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  5]\n",
      " [ 8 28]]\n"
     ]
    }
   ],
   "source": [
    "#view the Confusion Matrix\n",
    "print(confusion_matrix(ensemble_predictions, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  7]\n",
      " [ 8 26]]\n"
     ]
    }
   ],
   "source": [
    "#this was the Confusion Matrix for the Decision Tree Model\n",
    "print(confusion_matrix(dectree_predictions, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  3]\n",
      " [10 30]]\n"
     ]
    }
   ],
   "source": [
    "#and for the Logistic Regression model, the Confusion Matrix was\n",
    "print(confusion_matrix(log_predictions, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble model produced a more balanced Confusion Matrix than either model alone.\n",
    "\n",
    "20 = number of samples 'heart disease absent' was predicted accurately for.\n",
    "\n",
    "28 = number of samples 'heart disease present' was predicted accurately for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75        28\n",
      "           1       0.78      0.85      0.81        33\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.79      0.78      0.78        61\n",
      "weighted avg       0.79      0.79      0.79        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print for the ensemble model\n",
    "print(classification_report(y_val,ensemble_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73        28\n",
      "           1       0.76      0.79      0.78        33\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.75      0.75      0.75        61\n",
      "weighted avg       0.75      0.75      0.75        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print for the decision tree model\n",
    "print(classification_report(y_val,dectree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.73        28\n",
      "           1       0.75      0.91      0.82        33\n",
      "\n",
      "    accuracy                           0.79        61\n",
      "   macro avg       0.80      0.78      0.78        61\n",
      "weighted avg       0.80      0.79      0.78        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print for the logistic regression model\n",
    "print(classification_report(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble model made a more balanced set of predictions (not significantly higher than either model alone though)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Area Under the Curve**\n",
    "\n",
    "A score of 1.0 represents a perfect classifier.\n",
    "\n",
    "A score of 0.5 represents a classifier that is as good as random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7813852813852814\n"
     ]
    }
   ],
   "source": [
    "#The AOC for the ensemble model\n",
    "print(roc_auc_score(y_val,ensemble_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751082251082251\n"
     ]
    }
   ],
   "source": [
    "#The AOC for the decision tree model\n",
    "print(roc_auc_score(y_val,dectree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775974025974026\n"
     ]
    }
   ],
   "source": [
    "#The AOC for the logistic regression model\n",
    "print(roc_auc_score(y_val,log_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble model performs slightly better on this measure than either model alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Ensemble Model Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0623\n",
       "                \n",
       "                    &plusmn; 0.0636\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0623\n",
       "                \n",
       "                    &plusmn; 0.0525\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0590\n",
       "                \n",
       "                    &plusmn; 0.0675\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.85%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0459\n",
       "                \n",
       "                    &plusmn; 0.0482\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0131\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 93.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0131\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 90.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0230\n",
       "                \n",
       "                    &plusmn; 0.0608\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(ensemble_model, random_state=1).fit(X_val, y_val)\n",
    "ensemble_feat_importance = eli5.show_weights(perm, feature_names = X_val.columns.tolist())\n",
    "ensemble_feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0622\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0492\n",
       "                \n",
       "                    &plusmn; 0.0415\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0393\n",
       "                \n",
       "                    &plusmn; 0.0533\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0564\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0328\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0295\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0131\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0066\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0098\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 89.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0262\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this was the decision tree model feature importance\n",
    "dectree_feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0656\n",
       "                \n",
       "                    &plusmn; 0.0508\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0623\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0426\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0393\n",
       "                \n",
       "                    &plusmn; 0.0262\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0814\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0230\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0197\n",
       "                \n",
       "                    &plusmn; 0.0245\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0293\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0393\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0033\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0033\n",
       "                \n",
       "                    &plusmn; 0.0865\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this was the logistic regression model feature importance\n",
    "log_feat_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble model provided slighly better accuracy than the Decision Tree or Logistic Regression models alone.\n",
    "\n",
    "The biggest advantage of using the ensemble model, is that any variance/bias in the data is mitigated.\n",
    "\n",
    "Therefore, because the model accuracy is moderately good (+75%), I would trust the ensemble model's predictions the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Enemble Model's Predictions on the Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704918032786885\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(ensemble_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  8]\n",
      " [ 6 25]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ensemble_predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        28\n",
      "           1       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.77        61\n",
      "   macro avg       0.77      0.77      0.77        61\n",
      "weighted avg       0.77      0.77      0.77        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ensemble_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the AOC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7716450216450217\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test,ensemble_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0754\n",
       "                \n",
       "                    &plusmn; 0.0765\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                oldpeak\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0689\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ca\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.0321\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thalach\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0361\n",
       "                \n",
       "                    &plusmn; 0.1024\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cp\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0262\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                exang\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                thal\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.13%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0207\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                trestbps\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                sex\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                age\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0334\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                chol\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0066\n",
       "                \n",
       "                    &plusmn; 0.0161\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                slope\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                restecg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                fbs\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(ensemble_model, random_state=1).fit(X_test, y_test)\n",
    "ensemble_feat_importance_test = eli5.show_weights(perm, feature_names = X_test.columns.tolist())\n",
    "ensemble_feat_importance_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Thoughts:\n",
    "\n",
    "With additional time devoted to this project, I would investigate hyper-parameter tuning.\n",
    "\n",
    "Some areas to explore are:\n",
    "\n",
    "1. Drop features that are less important and then re-evaluate on the validation data.\n",
    "\n",
    "2. Take a closer look at the CA (number of major vessels observed) and the CP (chest pain type) features.\n",
    "\n",
    "\n",
    "*The documentation suggests the data will show CA values from 0 - 3 and CP values from 1 - 4. But values from 0 - 4 are present for both features.* \n",
    "\n",
    "*I wondered if \"0\" CA value actually means the patient didn't have a this test, because a majority of the patients have this value.*\n",
    "\n",
    "*Internet research and reviewing other developer's analysis of this dataset reveals that a \"0\" CP value is interpreted as no chest pain.*\n",
    "\n",
    "*For next steps, I could drop the \"0\" values for these features and see how that impacts the model accuracy.*\n",
    "\n",
    "3. Use techniques to generate additional data (bootstrapping, creating synthetic values).\n",
    "\n",
    "These are techniques I will employ in future projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
