{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here are some things I am curious about, after exploring the data:**\n",
    "1. Do any of the features strongly predict heart disease on their own?\n",
    "2. Which combinations of features boost heart disease prediction the most?\n",
    "3. Are any of the features less related...unless combined with others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[how to examine permutation (feature) importance](https://www.kaggle.com/dansbecker/permutation-importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But first, I need to select an appropriate machine learning algorithm.**\n",
    "\n",
    "[These are the important considerations:](https://www.kdnuggets.com/2020/05/guide-choose-right-machine-learning-algorithm.html#:~:text=%20An%20easy%20guide%20to%20choose%20the%20right,time.%20Higher%20accuracy%20typically%20means%20higher...%20More%20)\n",
    "\n",
    "1. *Size of the training data (small in this case)*\n",
    "\n",
    "    if the training data is smal or if the dataset has a small number of observations/high number of features \n",
    "    choose algorithms with high bias/low variance like Linear regression, Naïve Bayes, or Linear SVM.\n",
    "    \n",
    "    If the training data is large and the number of observations is higher, compared to the number of \n",
    "    features, you can use low bias/high variance algorithms like KNN, Decision trees, or kernel SVM.\n",
    "    \n",
    "\n",
    "2. *Desired Accuracy and/or Interpretability of the output (interpretability in this case)*\n",
    "\n",
    "    Accuracy of a model means that the function predicts a response value for a given observation, which is \n",
    "    close to the true response value for that observation. \n",
    "    \n",
    "    A highly interpretable algorithm (restrictive models like Linear Regression) means that one can easily \n",
    "    understand how any individual predictor is associated with the response while the flexible models give \n",
    "    higher accuracy at the cost of low interpretability.\n",
    "    \n",
    "    \n",
    "3.  *Speed or Training time (non-issue for this small dataset)*\n",
    "\n",
    "    Higher accuracy typically means higher training time. Also, algorithms require more time to train on \n",
    "    large training data. In real-world applications, the choice of algorithm is driven by these two factors \n",
    "    predominantly.\n",
    "\n",
    "    Algorithms like Naïve Bayes and Linear and Logistic regression are easy to implement and quick to run. \n",
    "    Algorithms like SVM, which involve tuning of parameters, Neural networks with high convergence time, and \n",
    "    random forests, need a lot of time to train the data.\n",
    "    \n",
    "    \n",
    "4. *Linearity (to be determined)*\n",
    "\n",
    "    The best way to find out the linearity is to either fit a linear line or run a logistic regression or SVM \n",
    "    and check for residual errors. A higher error means the data is not linear and would need complex \n",
    "    algorithms to fit.\n",
    "    \n",
    "\n",
    "5. *Number of features (small in this case)*\n",
    "\n",
    "    The dataset may have a large number of features that may not all be relevant and significant. For a \n",
    "    certain type of data, such as genetics or textual, the number of features can be very large compared to \n",
    "    the number of data points.\n",
    "    \n",
    "\n",
    "6. *Supervised or Unsupervised learning (Supervised in this case)*\n",
    "\n",
    "   Supervised learning algorithms are used when the training data has output variables corresponding to the \n",
    "   input variables. The algorithm analyses the input data and learns a function to map the relationship \n",
    "   between the input and output variables.\n",
    "   \n",
    "   Unspervised learning algorithms are used when the training data does not have a response variable. Such \n",
    "   algorithms try to find the intrinsic pattern and hidden structures in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I am going to start with a Linear or Logistic regression algorithm and evaluate whether the data is non-linear.**  \n",
    "\n",
    "If non-linear, I will apply random forests (because they are easy to interpret).\n",
    "\n",
    "[The choice between Linear or Logistic regression, depends on what type of output I am expecting:](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "\n",
    "I am expecting to output a category (Logistic Regression): yes - heart disease or no - not heart disease.\n",
    "\n",
    "I am not expecting to output a quantity (Linear Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit my data to a logistic regression model\n",
    "\n",
    "[Instead of predicting exactly 0 or 1, logistic regression generates a probability—a value between 0 and 1, exclusive.](https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "#import the dataset\n",
    "heart_data = pd.read_csv(\"data/heart.csv\")\n",
    "\n",
    "#preview the columns\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data for the model by:**\n",
    "1. determining the target\n",
    "2. separating the features from the label \n",
    "3. splitting out the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Determine the target (y) and separate label (y) from features (X)\n",
    "target = 'target'\n",
    "y = heart_data[target]\n",
    "X = heart_data.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate out Train Set from Test Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a variable called ml_model and use it to call the logistic regression classifer\n",
    "ml_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "#fit the classifier to the training data - the training features and the training labels are passed in\n",
    "ml_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the predict command on the classifier and providing it with the parameters it needs to make predictions about\n",
    "#which are the features in your testing dataset\n",
    "predictions = ml_model.predict(X_test)\n",
    "overfit = ml_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Evaluate the Predictions**](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Logistic Regression outputs predictions about test data points on a binary scale, zero or one.](https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/#:~:text=The%20classification%20report%20is%20a%20Scikit-Learn%20built%20in,quick%20intuition%20of%20how%20your%20model%20is%20performing.)\n",
    "\n",
    "If the value of something is 0.5 or above, it is classified as belonging to class 1, while below 0.5 if is classified as belonging to 0.\n",
    "\n",
    "Each of the features also has a label of only 0 or 1. \n",
    "\n",
    "Logistic regression is a linear classifier and therefore used when there is some sort of linear relationship between the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8681318681318682\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score is the simplest way to evaluate how the model performs\n",
    "#pass in the predictions against the ground truth labels which were stored in the test labels\n",
    "print(accuracy_score(predictions, y_test))\n",
    "\n",
    "#While it can give you a quick idea of how your classifier is performing\n",
    "#it is best used when the number of observations/examples in each class is roughly equivalent.\n",
    "#Because this doesn't happen very often, you're probably better off using another metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  4]\n",
      " [ 8 40]]\n"
     ]
    }
   ],
   "source": [
    "# The Confusion Matrix and Classification Report give more details about performance\n",
    "print(confusion_matrix(predictions, y_test))\n",
    "\n",
    "#the number of correct predictions for each class run on the diagonal from top-left to bottom-right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        47\n",
      "           1       0.83      0.91      0.87        44\n",
      "\n",
      "    accuracy                           0.87        91\n",
      "   macro avg       0.87      0.87      0.87        91\n",
      "weighted avg       0.87      0.87      0.87        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81        91\n",
      "           1       0.83      0.93      0.88       121\n",
      "\n",
      "    accuracy                           0.85       212\n",
      "   macro avg       0.86      0.84      0.85       212\n",
      "weighted avg       0.86      0.85      0.85       212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,overfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694390715667311\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8405685223867042\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_train,overfit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
